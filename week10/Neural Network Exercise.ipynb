{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "0d831181-2971-518c-9d49-2af4b48d522b"
   },
   "source": [
    "MLPClassifier example "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "c8e186df-a808-e0ee-d017-db14b6b0f78d"
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "c3dc65a7-d559-37bd-0757-55608b8c9889"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load in the file Dataset_spine.csv\n",
    "\n",
    "- Use Pandas\n",
    "- Drop the column Unnamed: 13\n",
    "\n",
    "Always inspect the dataframe using .head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "dc573a8d-981e-bcf8-93d0-27041c3157b3"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('Dataset_spine.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Col1</th>\n",
       "      <th>Col2</th>\n",
       "      <th>Col3</th>\n",
       "      <th>Col4</th>\n",
       "      <th>Col5</th>\n",
       "      <th>Col6</th>\n",
       "      <th>Col7</th>\n",
       "      <th>Col8</th>\n",
       "      <th>Col9</th>\n",
       "      <th>Col10</th>\n",
       "      <th>Col11</th>\n",
       "      <th>Col12</th>\n",
       "      <th>Class_att</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63.027817</td>\n",
       "      <td>22.552586</td>\n",
       "      <td>39.609117</td>\n",
       "      <td>40.475232</td>\n",
       "      <td>98.672917</td>\n",
       "      <td>-0.254400</td>\n",
       "      <td>0.744503</td>\n",
       "      <td>12.5661</td>\n",
       "      <td>14.5386</td>\n",
       "      <td>15.30468</td>\n",
       "      <td>-28.658501</td>\n",
       "      <td>43.5123</td>\n",
       "      <td>Abnormal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>39.056951</td>\n",
       "      <td>10.060991</td>\n",
       "      <td>25.015378</td>\n",
       "      <td>28.995960</td>\n",
       "      <td>114.405425</td>\n",
       "      <td>4.564259</td>\n",
       "      <td>0.415186</td>\n",
       "      <td>12.8874</td>\n",
       "      <td>17.5323</td>\n",
       "      <td>16.78486</td>\n",
       "      <td>-25.530607</td>\n",
       "      <td>16.1102</td>\n",
       "      <td>Abnormal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>68.832021</td>\n",
       "      <td>22.218482</td>\n",
       "      <td>50.092194</td>\n",
       "      <td>46.613539</td>\n",
       "      <td>105.985135</td>\n",
       "      <td>-3.530317</td>\n",
       "      <td>0.474889</td>\n",
       "      <td>26.8343</td>\n",
       "      <td>17.4861</td>\n",
       "      <td>16.65897</td>\n",
       "      <td>-29.031888</td>\n",
       "      <td>19.2221</td>\n",
       "      <td>Abnormal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>69.297008</td>\n",
       "      <td>24.652878</td>\n",
       "      <td>44.311238</td>\n",
       "      <td>44.644130</td>\n",
       "      <td>101.868495</td>\n",
       "      <td>11.211523</td>\n",
       "      <td>0.369345</td>\n",
       "      <td>23.5603</td>\n",
       "      <td>12.7074</td>\n",
       "      <td>11.42447</td>\n",
       "      <td>-30.470246</td>\n",
       "      <td>18.8329</td>\n",
       "      <td>Abnormal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>49.712859</td>\n",
       "      <td>9.652075</td>\n",
       "      <td>28.317406</td>\n",
       "      <td>40.060784</td>\n",
       "      <td>108.168725</td>\n",
       "      <td>7.918501</td>\n",
       "      <td>0.543360</td>\n",
       "      <td>35.4940</td>\n",
       "      <td>15.9546</td>\n",
       "      <td>8.87237</td>\n",
       "      <td>-16.378376</td>\n",
       "      <td>24.9171</td>\n",
       "      <td>Abnormal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Col1       Col2       Col3       Col4        Col5       Col6  \\\n",
       "0  63.027817  22.552586  39.609117  40.475232   98.672917  -0.254400   \n",
       "1  39.056951  10.060991  25.015378  28.995960  114.405425   4.564259   \n",
       "2  68.832021  22.218482  50.092194  46.613539  105.985135  -3.530317   \n",
       "3  69.297008  24.652878  44.311238  44.644130  101.868495  11.211523   \n",
       "4  49.712859   9.652075  28.317406  40.060784  108.168725   7.918501   \n",
       "\n",
       "       Col7     Col8     Col9     Col10      Col11    Col12 Class_att  \n",
       "0  0.744503  12.5661  14.5386  15.30468 -28.658501  43.5123  Abnormal  \n",
       "1  0.415186  12.8874  17.5323  16.78486 -25.530607  16.1102  Abnormal  \n",
       "2  0.474889  26.8343  17.4861  16.65897 -29.031888  19.2221  Abnormal  \n",
       "3  0.369345  23.5603  12.7074  11.42447 -30.470246  18.8329  Abnormal  \n",
       "4  0.543360  35.4940  15.9546   8.87237 -16.378376  24.9171  Abnormal  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also drop ['Col7','Col8','Col9','Col10','Col11','Col12']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "_cell_guid": "459fd9ba-8900-9b29-0317-23d8abf034c4"
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "# Drop the columns listed in columns_to_drop if they exist\n",
    "columns_to_drop = ['Col7', 'Col8', 'Col9', 'Col10', 'Col11', 'Col12']\n",
    "existing_columns = [col for col in columns_to_drop if col in df.columns]\n",
    "if existing_columns:\n",
    "    df = df.drop(existing_columns, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_cell_guid": "8fefbd23-d73b-0544-f540-c01f8cd24cb7"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Col1</th>\n",
       "      <th>Col2</th>\n",
       "      <th>Col3</th>\n",
       "      <th>Col4</th>\n",
       "      <th>Col5</th>\n",
       "      <th>Col6</th>\n",
       "      <th>Class_att</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63.027817</td>\n",
       "      <td>22.552586</td>\n",
       "      <td>39.609117</td>\n",
       "      <td>40.475232</td>\n",
       "      <td>98.672917</td>\n",
       "      <td>-0.254400</td>\n",
       "      <td>Abnormal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>39.056951</td>\n",
       "      <td>10.060991</td>\n",
       "      <td>25.015378</td>\n",
       "      <td>28.995960</td>\n",
       "      <td>114.405425</td>\n",
       "      <td>4.564259</td>\n",
       "      <td>Abnormal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>68.832021</td>\n",
       "      <td>22.218482</td>\n",
       "      <td>50.092194</td>\n",
       "      <td>46.613539</td>\n",
       "      <td>105.985135</td>\n",
       "      <td>-3.530317</td>\n",
       "      <td>Abnormal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>69.297008</td>\n",
       "      <td>24.652878</td>\n",
       "      <td>44.311238</td>\n",
       "      <td>44.644130</td>\n",
       "      <td>101.868495</td>\n",
       "      <td>11.211523</td>\n",
       "      <td>Abnormal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>49.712859</td>\n",
       "      <td>9.652075</td>\n",
       "      <td>28.317406</td>\n",
       "      <td>40.060784</td>\n",
       "      <td>108.168725</td>\n",
       "      <td>7.918501</td>\n",
       "      <td>Abnormal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Col1       Col2       Col3       Col4        Col5       Col6 Class_att\n",
       "0  63.027817  22.552586  39.609117  40.475232   98.672917  -0.254400  Abnormal\n",
       "1  39.056951  10.060991  25.015378  28.995960  114.405425   4.564259  Abnormal\n",
       "2  68.832021  22.218482  50.092194  46.613539  105.985135  -3.530317  Abnormal\n",
       "3  69.297008  24.652878  44.311238  44.644130  101.868495  11.211523  Abnormal\n",
       "4  49.712859   9.652075  28.317406  40.060784  108.168725   7.918501  Abnormal"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will show the classes, obviously that column will be our y, the rest will be X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Abnormal', 'Normal'], dtype=object)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Class_att\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Binary Classifier\n",
    "\n",
    "import the things we need from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "train_test_split\n",
    "confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "1f01b202-9cac-dcc8-0831-99b7241e992c"
   },
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the variables X and y by picking the columns as discussed above\n",
    "\n",
    "Do a train_test_split, use a fixed random_state and make the test_size be 25%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "_cell_guid": "d817746f-8582-c3dc-dd14-822830337eba",
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "# Set X as all columns except 'Class_att'\n",
    "X = df.drop('Class_att', axis=1)\n",
    "\n",
    "# Set y as the 'Class_att' column\n",
    "y = df['Class_att']\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "_cell_guid": "9c99af5c-3f0a-136e-a870-77245031f393"
   },
   "outputs": [],
   "source": [
    "# Perform train-test split with 25% test size and fixed random state\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (232, 6)\n",
      "X_test shape: (78, 6)\n",
      "y_train shape: (232,)\n",
      "y_test shape: (78,)\n"
     ]
    }
   ],
   "source": [
    "# Print shapes to verify the split\n",
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"X_test shape: {X_test.shape}\")\n",
    "print(f\"y_train shape: {y_train.shape}\")\n",
    "print(f\"y_test shape: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets use MLPClassifier from sklearn\n",
    "\n",
    "Do for 3 hidden layers with 100 units in each\n",
    "\n",
    "set tol=0.000000001\n",
    "\n",
    "use solver 'sgd'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the MLPClassifier with specified parameters\n",
    "mlp = MLPClassifier(\n",
    "    hidden_layer_sizes=(100, 100, 100),  # 3 hidden layers with 100 units each\n",
    "    tol=0.000000001,                     # Very small tolerance\n",
    "    solver='sgd',                        # Stochastic gradient descent\n",
    "    random_state=42                      # For reproducibility\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fit the classifier using training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "_cell_guid": "c992c033-ef51-ce74-fe22-94394c05759a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of iterations: 52\n",
      "Loss: 0.34975704079039704\n"
     ]
    }
   ],
   "source": [
    "# Fit the MLPClassifier on the training data\n",
    "mlp.fit(X_train, y_train)\n",
    "\n",
    "# Print out the training details\n",
    "print(f\"Number of iterations: {mlp.n_iter_}\")\n",
    "print(f\"Loss: {mlp.loss_}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get y_pred using .predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First few predictions: ['Abnormal' 'Normal' 'Abnormal' 'Abnormal' 'Abnormal']\n",
      "Shape of predictions: (78,)\n"
     ]
    }
   ],
   "source": [
    "# Get predictions using the trained model\n",
    "y_pred = mlp.predict(X_test)\n",
    "\n",
    "# Print the first few predictions\n",
    "print(\"First few predictions:\", y_pred[:5])\n",
    "print(f\"Shape of predictions: {y_pred.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "20c44ff4-bd47-4b67-1e09-830561670d27"
   },
   "source": [
    "Get the accuracy score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7564\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Get accuracy score by comparing predictions to actual values\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "_cell_guid": "aeda713a-6dbc-fcc4-be5a-c6e0fb35d71b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[53  4]\n",
      " [15  6]]\n"
     ]
    }
   ],
   "source": [
    "# Calculate the confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Display the confusion matrix\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's view a heatmap with the confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "_cell_guid": "8bc84c75-5959-bfcb-1ae1-2994ddafdbb5"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(cm, center=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow\n",
    "\n",
    "Now what about Tensorflow??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-24 15:20:36.922041: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-03-24 15:20:36.936088: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1742829636.951659    6367 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1742829636.956110    6367 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1742829636.968877    6367 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1742829636.968895    6367 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1742829636.968898    6367 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1742829636.968900    6367 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-03-24 15:20:36.975273: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up a new sequential model, call it model_tf\n",
    "\n",
    "Have 3 hidden layers, each with activation relu\n",
    "\n",
    "have an output layer with only 1 unit, no activation function\n",
    "\n",
    "Should you also set up a normaliser as well. See example workbooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-24 15:22:31.372293: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n"
     ]
    }
   ],
   "source": [
    "# Create the TensorFlow sequential model\n",
    "model_tf = tf.keras.Sequential([\n",
    "    # Normalizing layer to standardize inputs\n",
    "    tf.keras.layers.Normalization(axis=-1),\n",
    "    \n",
    "    # Three hidden layers with ReLU activation\n",
    "    tf.keras.layers.Dense(100, activation='relu'),\n",
    "    tf.keras.layers.Dense(100, activation='relu'),\n",
    "    tf.keras.layers.Dense(100, activation='relu'),\n",
    "    \n",
    "    # Output layer with 1 unit, no activation (for binary classification)\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adapt the normalization layer to the training data\n",
    "model_tf.layers[0].adapt(X_train.values)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compile the model, pick an optimizer, use Adam or tf.keras.optimizers.experimental.SGD(0.001). loss is binarycrossentropy\n",
    "\n",
    "    metrics=['accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model with Adam optimizer and binary crossentropy loss\n",
    "model_tf.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(0.001),\n",
    "    loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "    metrics=['accuracy']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "140    Abnormal\n",
       "208    Abnormal\n",
       "278      Normal\n",
       "203    Abnormal\n",
       "144    Abnormal\n",
       "         ...   \n",
       "188    Abnormal\n",
       "71     Abnormal\n",
       "106    Abnormal\n",
       "270      Normal\n",
       "102    Abnormal\n",
       "Name: Class_att, Length: 232, dtype: object"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now try fitting, 20 epochs, do \n",
    "\n",
    "    X_train.values, y_train.values, epochs=20, validation_split=0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-24 15:23:12.932555: W tensorflow/core/framework/op_kernel.cc:1833] OP_REQUIRES failed at cast_op.cc:122 : UNIMPLEMENTED: Cast string to float is not supported\n"
     ]
    },
    {
     "ename": "UnimplementedError",
     "evalue": "Graph execution error:\n\nDetected at node compile_loss/binary_crossentropy/Cast defined at (most recent call last):\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\n\n  File \"<frozen runpy>\", line 88, in _run_code\n\n  File \"/home/codespace/.local/lib/python3.12/site-packages/ipykernel_launcher.py\", line 18, in <module>\n\n  File \"/home/codespace/.local/lib/python3.12/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n\n  File \"/home/codespace/.local/lib/python3.12/site-packages/ipykernel/kernelapp.py\", line 739, in start\n\n  File \"/home/codespace/.local/lib/python3.12/site-packages/tornado/platform/asyncio.py\", line 205, in start\n\n  File \"/usr/local/python/3.12.1/lib/python3.12/asyncio/base_events.py\", line 638, in run_forever\n\n  File \"/usr/local/python/3.12.1/lib/python3.12/asyncio/base_events.py\", line 1971, in _run_once\n\n  File \"/usr/local/python/3.12.1/lib/python3.12/asyncio/events.py\", line 84, in _run\n\n  File \"/home/codespace/.local/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n\n  File \"/home/codespace/.local/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n\n  File \"/home/codespace/.local/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n\n  File \"/home/codespace/.local/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 362, in execute_request\n\n  File \"/home/codespace/.local/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n\n  File \"/home/codespace/.local/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 449, in do_execute\n\n  File \"/home/codespace/.local/lib/python3.12/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n\n  File \"/home/codespace/.local/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3075, in run_cell\n\n  File \"/home/codespace/.local/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3130, in _run_cell\n\n  File \"/home/codespace/.local/lib/python3.12/site-packages/IPython/core/async_helpers.py\", line 128, in _pseudo_sync_runner\n\n  File \"/home/codespace/.local/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3334, in run_cell_async\n\n  File \"/home/codespace/.local/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3517, in run_ast_nodes\n\n  File \"/home/codespace/.local/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3577, in run_code\n\n  File \"/tmp/ipykernel_6367/527915436.py\", line 2, in <module>\n\n  File \"/usr/local/python/3.12.1/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/usr/local/python/3.12.1/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py\", line 371, in fit\n\n  File \"/usr/local/python/3.12.1/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py\", line 219, in function\n\n  File \"/usr/local/python/3.12.1/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py\", line 132, in multi_step_on_iterator\n\n  File \"/usr/local/python/3.12.1/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py\", line 113, in one_step_on_data\n\n  File \"/usr/local/python/3.12.1/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py\", line 60, in train_step\n\n  File \"/usr/local/python/3.12.1/lib/python3.12/site-packages/keras/src/trainers/trainer.py\", line 383, in _compute_loss\n\n  File \"/usr/local/python/3.12.1/lib/python3.12/site-packages/keras/src/trainers/trainer.py\", line 351, in compute_loss\n\n  File \"/usr/local/python/3.12.1/lib/python3.12/site-packages/keras/src/trainers/compile_utils.py\", line 690, in __call__\n\n  File \"/usr/local/python/3.12.1/lib/python3.12/site-packages/keras/src/trainers/compile_utils.py\", line 699, in call\n\n  File \"/usr/local/python/3.12.1/lib/python3.12/site-packages/keras/src/losses/loss.py\", line 63, in __call__\n\n  File \"/usr/local/python/3.12.1/lib/python3.12/site-packages/keras/src/tree/tree_api.py\", line 192, in map_structure\n\n  File \"/usr/local/python/3.12.1/lib/python3.12/site-packages/keras/src/tree/optree_impl.py\", line 108, in map_structure\n\n  File \"/usr/local/python/3.12.1/lib/python3.12/site-packages/optree/ops.py\", line 766, in tree_map\n\n  File \"/usr/local/python/3.12.1/lib/python3.12/site-packages/keras/src/losses/loss.py\", line 64, in <lambda>\n\n  File \"/usr/local/python/3.12.1/lib/python3.12/site-packages/keras/src/ops/core.py\", line 958, in convert_to_tensor\n\n  File \"/usr/local/python/3.12.1/lib/python3.12/site-packages/keras/src/backend/tensorflow/core.py\", line 147, in convert_to_tensor\n\nCast string to float is not supported\n\t [[{{node compile_loss/binary_crossentropy/Cast}}]] [Op:__inference_multi_step_on_iterator_1966]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnimplementedError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[34], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Fit the model using 20 epochs and a 20% validation split\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_tf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\n\u001b[1;32m      7\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/python/3.12.1/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/usr/local/python/3.12.1/lib/python3.12/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mUnimplementedError\u001b[0m: Graph execution error:\n\nDetected at node compile_loss/binary_crossentropy/Cast defined at (most recent call last):\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\n\n  File \"<frozen runpy>\", line 88, in _run_code\n\n  File \"/home/codespace/.local/lib/python3.12/site-packages/ipykernel_launcher.py\", line 18, in <module>\n\n  File \"/home/codespace/.local/lib/python3.12/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n\n  File \"/home/codespace/.local/lib/python3.12/site-packages/ipykernel/kernelapp.py\", line 739, in start\n\n  File \"/home/codespace/.local/lib/python3.12/site-packages/tornado/platform/asyncio.py\", line 205, in start\n\n  File \"/usr/local/python/3.12.1/lib/python3.12/asyncio/base_events.py\", line 638, in run_forever\n\n  File \"/usr/local/python/3.12.1/lib/python3.12/asyncio/base_events.py\", line 1971, in _run_once\n\n  File \"/usr/local/python/3.12.1/lib/python3.12/asyncio/events.py\", line 84, in _run\n\n  File \"/home/codespace/.local/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n\n  File \"/home/codespace/.local/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n\n  File \"/home/codespace/.local/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n\n  File \"/home/codespace/.local/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 362, in execute_request\n\n  File \"/home/codespace/.local/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n\n  File \"/home/codespace/.local/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 449, in do_execute\n\n  File \"/home/codespace/.local/lib/python3.12/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n\n  File \"/home/codespace/.local/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3075, in run_cell\n\n  File \"/home/codespace/.local/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3130, in _run_cell\n\n  File \"/home/codespace/.local/lib/python3.12/site-packages/IPython/core/async_helpers.py\", line 128, in _pseudo_sync_runner\n\n  File \"/home/codespace/.local/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3334, in run_cell_async\n\n  File \"/home/codespace/.local/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3517, in run_ast_nodes\n\n  File \"/home/codespace/.local/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3577, in run_code\n\n  File \"/tmp/ipykernel_6367/527915436.py\", line 2, in <module>\n\n  File \"/usr/local/python/3.12.1/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/usr/local/python/3.12.1/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py\", line 371, in fit\n\n  File \"/usr/local/python/3.12.1/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py\", line 219, in function\n\n  File \"/usr/local/python/3.12.1/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py\", line 132, in multi_step_on_iterator\n\n  File \"/usr/local/python/3.12.1/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py\", line 113, in one_step_on_data\n\n  File \"/usr/local/python/3.12.1/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py\", line 60, in train_step\n\n  File \"/usr/local/python/3.12.1/lib/python3.12/site-packages/keras/src/trainers/trainer.py\", line 383, in _compute_loss\n\n  File \"/usr/local/python/3.12.1/lib/python3.12/site-packages/keras/src/trainers/trainer.py\", line 351, in compute_loss\n\n  File \"/usr/local/python/3.12.1/lib/python3.12/site-packages/keras/src/trainers/compile_utils.py\", line 690, in __call__\n\n  File \"/usr/local/python/3.12.1/lib/python3.12/site-packages/keras/src/trainers/compile_utils.py\", line 699, in call\n\n  File \"/usr/local/python/3.12.1/lib/python3.12/site-packages/keras/src/losses/loss.py\", line 63, in __call__\n\n  File \"/usr/local/python/3.12.1/lib/python3.12/site-packages/keras/src/tree/tree_api.py\", line 192, in map_structure\n\n  File \"/usr/local/python/3.12.1/lib/python3.12/site-packages/keras/src/tree/optree_impl.py\", line 108, in map_structure\n\n  File \"/usr/local/python/3.12.1/lib/python3.12/site-packages/optree/ops.py\", line 766, in tree_map\n\n  File \"/usr/local/python/3.12.1/lib/python3.12/site-packages/keras/src/losses/loss.py\", line 64, in <lambda>\n\n  File \"/usr/local/python/3.12.1/lib/python3.12/site-packages/keras/src/ops/core.py\", line 958, in convert_to_tensor\n\n  File \"/usr/local/python/3.12.1/lib/python3.12/site-packages/keras/src/backend/tensorflow/core.py\", line 147, in convert_to_tensor\n\nCast string to float is not supported\n\t [[{{node compile_loss/binary_crossentropy/Cast}}]] [Op:__inference_multi_step_on_iterator_1966]"
     ]
    }
   ],
   "source": [
    "# Fit the model using 20 epochs and a 20% validation split\n",
    "history = model_tf.fit(\n",
    "    X_train.values, \n",
    "    y_train.values, \n",
    "    epochs=20, \n",
    "    validation_split=0.2\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " You should get a bunch of errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why this error?\n",
    "\n",
    "Well look at y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "140    Abnormal\n",
       "208    Abnormal\n",
       "278      Normal\n",
       "203    Abnormal\n",
       "144    Abnormal\n",
       "         ...   \n",
       "188    Abnormal\n",
       "71     Abnormal\n",
       "106    Abnormal\n",
       "270      Normal\n",
       "102    Abnormal\n",
       "Name: Class_att, Length: 232, dtype: object"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "They're not numbers, we need to convert those to numbers. Using LabelEncoder\n",
    "\n",
    "Scikit-learn didn't care, but Tensorflow is a \"lower-level\" programming tool so you need to do the conversion yourself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes mapping:\n",
      "Abnormal -> 0\n",
      "Normal -> 1\n"
     ]
    }
   ],
   "source": [
    "# your code here\n",
    "# Create a LabelEncoder to convert string labels to numbers\n",
    "label_encoder = preprocessing.LabelEncoder()\n",
    "\n",
    "# Fit the encoder on the unique classes in our data\n",
    "label_encoder.fit(df[\"Class_att\"].unique())\n",
    "\n",
    "# Display the classes and their numerical mappings\n",
    "print(\"Classes mapping:\")\n",
    "for i, label in enumerate(label_encoder.classes_):\n",
    "    print(f\"{label} -> {i}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit the label encoder on y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes mapping after fitting on y_train:\n",
      "Abnormal -> 0\n",
      "Normal -> 1\n"
     ]
    }
   ],
   "source": [
    "# Fit the label encoder on y_train (already created in previous cell)\n",
    "label_encoder.fit(y_train)\n",
    "\n",
    "# Check the mapping again to confirm it's correctly set\n",
    "print(\"Classes mapping after fitting on y_train:\")\n",
    "for i, label in enumerate(label_encoder.classes_):\n",
    "    print(f\"{label} -> {i}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now transform both y_train and y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train_enc shape: (232,)\n",
      "y_test_enc shape: (78,)\n",
      "First few values of y_train_enc: [0 0 1 0 0]\n",
      "First few values of y_test_enc: [1 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "# Transform the train and test labels to numeric values\n",
    "y_train_enc = label_encoder.transform(y_train)\n",
    "y_test_enc = label_encoder.transform(y_test)\n",
    "\n",
    "# Print the shapes to verify the transformation\n",
    "print(f\"y_train_enc shape: {y_train_enc.shape}\")\n",
    "print(f\"y_test_enc shape: {y_test_enc.shape}\")\n",
    "print(f\"First few values of y_train_enc: {y_train_enc[:5]}\")\n",
    "print(f\"First few values of y_test_enc: {y_test_enc[:5]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1,\n",
       "       0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0,\n",
       "       1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1,\n",
       "       0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0,\n",
       "       0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1,\n",
       "       0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0,\n",
       "       1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0,\n",
       "       0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1,\n",
       "       0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1,\n",
       "       0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0,\n",
       "       0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_enc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting again\n",
    "\n",
    "Try fitting your model again with y_train_enc. It should work now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - accuracy: 0.6442 - loss: 0.6660 - val_accuracy: 0.6596 - val_loss: 0.5804\n",
      "Epoch 2/20\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6372 - loss: 0.5638 - val_accuracy: 0.6596 - val_loss: 0.4999\n",
      "Epoch 3/20\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6643 - loss: 0.4862 - val_accuracy: 0.7660 - val_loss: 0.4254\n",
      "Epoch 4/20\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7309 - loss: 0.4145 - val_accuracy: 0.8511 - val_loss: 0.3704\n",
      "Epoch 5/20\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7748 - loss: 0.4155 - val_accuracy: 0.8936 - val_loss: 0.3385\n",
      "Epoch 6/20\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8760 - loss: 0.3240 - val_accuracy: 0.8936 - val_loss: 0.3163\n",
      "Epoch 7/20\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8388 - loss: 0.3439 - val_accuracy: 0.9362 - val_loss: 0.2951\n",
      "Epoch 8/20\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8391 - loss: 0.3388 - val_accuracy: 0.9574 - val_loss: 0.2787\n",
      "Epoch 9/20\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8766 - loss: 0.2978 - val_accuracy: 0.9574 - val_loss: 0.2614\n",
      "Epoch 10/20\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8614 - loss: 0.2930 - val_accuracy: 0.9362 - val_loss: 0.2497\n",
      "Epoch 11/20\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8748 - loss: 0.2573 - val_accuracy: 0.9362 - val_loss: 0.2365\n",
      "Epoch 12/20\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8636 - loss: 0.2494 - val_accuracy: 0.9574 - val_loss: 0.2256\n",
      "Epoch 13/20\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8903 - loss: 0.2504 - val_accuracy: 0.9362 - val_loss: 0.2209\n",
      "Epoch 14/20\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8808 - loss: 0.2581 - val_accuracy: 0.9362 - val_loss: 0.2227\n",
      "Epoch 15/20\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8733 - loss: 0.2490 - val_accuracy: 0.9362 - val_loss: 0.2102\n",
      "Epoch 16/20\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8702 - loss: 0.2576 - val_accuracy: 0.9362 - val_loss: 0.2175\n",
      "Epoch 17/20\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9111 - loss: 0.2129 - val_accuracy: 0.9362 - val_loss: 0.2115\n",
      "Epoch 18/20\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8798 - loss: 0.2273 - val_accuracy: 0.9362 - val_loss: 0.2071\n",
      "Epoch 19/20\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8847 - loss: 0.2063 - val_accuracy: 0.9362 - val_loss: 0.2048\n",
      "Epoch 20/20\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8928 - loss: 0.2118 - val_accuracy: 0.9362 - val_loss: 0.2057\n"
     ]
    }
   ],
   "source": [
    "# your code here\n",
    "\n",
    "# Fit the model using the encoded training labels\n",
    "history = model_tf.fit(\n",
    "    X_train.values, \n",
    "    y_train_enc, \n",
    "    epochs=20, \n",
    "    validation_split=0.2\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy for both the training and validation sets is a little all over the place. Maybe we need more Epochs or some other way to decide when to finish. Anyway..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model_tf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  2.6300857 ],\n",
       "       [ -9.717553  ],\n",
       "       [ -0.29179832],\n",
       "       [ -8.602041  ],\n",
       "       [ -1.0934764 ],\n",
       "       [ -1.8783352 ],\n",
       "       [ -9.727088  ],\n",
       "       [ -5.2657    ],\n",
       "       [ -1.2545675 ],\n",
       "       [ -1.1344228 ],\n",
       "       [-15.300119  ],\n",
       "       [-11.998724  ],\n",
       "       [  1.4406996 ],\n",
       "       [  1.3767918 ],\n",
       "       [  2.638644  ],\n",
       "       [ -0.89231837],\n",
       "       [  0.52751344],\n",
       "       [ -9.767001  ],\n",
       "       [  0.84182847],\n",
       "       [ -9.023127  ],\n",
       "       [ -2.008309  ],\n",
       "       [ -9.490943  ],\n",
       "       [ -5.1368012 ],\n",
       "       [ -9.76389   ],\n",
       "       [-13.144083  ],\n",
       "       [-10.745456  ],\n",
       "       [ -7.046711  ],\n",
       "       [  0.26929706],\n",
       "       [  2.468438  ],\n",
       "       [  4.9320683 ],\n",
       "       [ -5.678052  ],\n",
       "       [ -1.6711421 ],\n",
       "       [ -6.6637797 ],\n",
       "       [  2.378792  ],\n",
       "       [ -4.9653845 ],\n",
       "       [ -4.1958942 ],\n",
       "       [ -0.26802307],\n",
       "       [  1.2536746 ],\n",
       "       [-12.785237  ],\n",
       "       [ -2.394401  ],\n",
       "       [  0.46880096],\n",
       "       [ -2.3370607 ],\n",
       "       [ -8.197299  ],\n",
       "       [  3.589066  ],\n",
       "       [  1.6647807 ],\n",
       "       [ -9.892539  ],\n",
       "       [  1.8133782 ],\n",
       "       [  1.9148161 ],\n",
       "       [ -1.7957395 ],\n",
       "       [ -8.52416   ],\n",
       "       [-11.260115  ],\n",
       "       [  2.1934948 ],\n",
       "       [ -4.9452386 ],\n",
       "       [ -7.00069   ],\n",
       "       [ -7.0738363 ],\n",
       "       [  1.399397  ],\n",
       "       [ -0.1241423 ],\n",
       "       [ -3.2299755 ],\n",
       "       [ -5.941459  ],\n",
       "       [ -0.7886458 ],\n",
       "       [  0.38098374],\n",
       "       [ -8.966515  ],\n",
       "       [ -2.7981794 ],\n",
       "       [ -3.472289  ],\n",
       "       [  0.60479224],\n",
       "       [  0.697078  ],\n",
       "       [-11.530954  ],\n",
       "       [ -2.7920237 ],\n",
       "       [ -6.4559083 ],\n",
       "       [  0.91196704],\n",
       "       [ -2.1095803 ],\n",
       "       [  1.5767223 ],\n",
       "       [ -5.1878533 ],\n",
       "       [ -1.4392    ],\n",
       "       [ -1.2103773 ],\n",
       "       [  0.86759156],\n",
       "       [ -2.0843375 ],\n",
       "       [ -5.7940183 ]], dtype=float32)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Those are not probabilities. Damn. Well we need to do some more\n",
    "\n",
    "We could have set the activation to sigmoid on the last layer and that would've given us probabilities but tensorflow manual says not to do that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_probs = tf.keras.activations.sigmoid(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's convert those probabilities to 0s or 1s. This is not the best way of doing this, Tensorflow almost certainly has something better, but this is how I want to do it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(y_probs, columns=[\"value\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "results[\"which\"] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.loc[results['value'] >= 0.5, 'which'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>value</th>\n",
       "      <th>which</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.932773</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000060</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.427564</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000184</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.250964</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>0.191669</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>0.229634</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>0.704244</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>0.110628</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>0.003036</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>78 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       value  which\n",
       "0   0.932773      1\n",
       "1   0.000060      0\n",
       "2   0.427564      0\n",
       "3   0.000184      0\n",
       "4   0.250964      0\n",
       "..       ...    ...\n",
       "73  0.191669      0\n",
       "74  0.229634      0\n",
       "75  0.704244      1\n",
       "76  0.110628      0\n",
       "77  0.003036      0\n",
       "\n",
       "[78 rows x 2 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1,\n",
       "       1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1,\n",
       "       0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.which.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "mistakes = (results.which.values != y_test_enc).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8528 - loss: 0.2864 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.30226102471351624, 0.8461538553237915]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_tf.evaluate(X_test, y_test_enc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.8333333333333334)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1-mistakes/78"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, it's worse than the sklearn implementation in test data but I haven't tried anything to tweak it, sklearn you will have noticed did more epochs in its training. It also didn't use any validation set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More Epochs! Lower learning rate\n",
    "\n",
    "I'm going to take the same basic structure and see what happens when I make some changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_tf = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(100,activation='relu'),\n",
    "    tf.keras.layers.Dense(100,activation='relu'),\n",
    "    tf.keras.layers.Dense(100,activation='relu'),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'll also do a lower learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_tf.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(0.0001),\n",
    "    loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lots and lots of epochs, let's run it and store the history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.3517 - loss: 2.0697 - val_accuracy: 0.5106 - val_loss: 1.0103\n",
      "Epoch 2/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5932 - loss: 0.9866 - val_accuracy: 0.6596 - val_loss: 0.9055\n",
      "Epoch 3/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6339 - loss: 0.9780 - val_accuracy: 0.6596 - val_loss: 0.6827\n",
      "Epoch 4/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6624 - loss: 0.6937 - val_accuracy: 0.7234 - val_loss: 0.4790\n",
      "Epoch 5/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7160 - loss: 0.5046 - val_accuracy: 0.8723 - val_loss: 0.4701\n",
      "Epoch 6/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7547 - loss: 0.4883 - val_accuracy: 0.8511 - val_loss: 0.4181\n",
      "Epoch 7/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7158 - loss: 0.4603 - val_accuracy: 0.8298 - val_loss: 0.3835\n",
      "Epoch 8/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6905 - loss: 0.4528 - val_accuracy: 0.8085 - val_loss: 0.3739\n",
      "Epoch 9/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7301 - loss: 0.4070 - val_accuracy: 0.8298 - val_loss: 0.3646\n",
      "Epoch 10/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7440 - loss: 0.3887 - val_accuracy: 0.8511 - val_loss: 0.3622\n",
      "Epoch 11/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8039 - loss: 0.3773 - val_accuracy: 0.8511 - val_loss: 0.3566\n",
      "Epoch 12/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8214 - loss: 0.3833 - val_accuracy: 0.8298 - val_loss: 0.3515\n",
      "Epoch 13/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7692 - loss: 0.3755 - val_accuracy: 0.8723 - val_loss: 0.3495\n",
      "Epoch 14/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8245 - loss: 0.3703 - val_accuracy: 0.8511 - val_loss: 0.3468\n",
      "Epoch 15/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8187 - loss: 0.3728 - val_accuracy: 0.8511 - val_loss: 0.3424\n",
      "Epoch 16/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8209 - loss: 0.3862 - val_accuracy: 0.8723 - val_loss: 0.3393\n",
      "Epoch 17/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8460 - loss: 0.3718 - val_accuracy: 0.8511 - val_loss: 0.3319\n",
      "Epoch 18/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8066 - loss: 0.3851 - val_accuracy: 0.8723 - val_loss: 0.3286\n",
      "Epoch 19/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8232 - loss: 0.3697 - val_accuracy: 0.8511 - val_loss: 0.3237\n",
      "Epoch 20/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8126 - loss: 0.3871 - val_accuracy: 0.8723 - val_loss: 0.3199\n",
      "Epoch 21/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8466 - loss: 0.3488 - val_accuracy: 0.8723 - val_loss: 0.3149\n",
      "Epoch 22/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8588 - loss: 0.3379 - val_accuracy: 0.8723 - val_loss: 0.3134\n",
      "Epoch 23/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8472 - loss: 0.3514 - val_accuracy: 0.8723 - val_loss: 0.3101\n",
      "Epoch 24/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8198 - loss: 0.3616 - val_accuracy: 0.8723 - val_loss: 0.3060\n",
      "Epoch 25/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8352 - loss: 0.3378 - val_accuracy: 0.8723 - val_loss: 0.3015\n",
      "Epoch 26/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8604 - loss: 0.3251 - val_accuracy: 0.8723 - val_loss: 0.2970\n",
      "Epoch 27/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8155 - loss: 0.3692 - val_accuracy: 0.8723 - val_loss: 0.3002\n",
      "Epoch 28/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8392 - loss: 0.3491 - val_accuracy: 0.8936 - val_loss: 0.2941\n",
      "Epoch 29/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8542 - loss: 0.3547 - val_accuracy: 0.8723 - val_loss: 0.2883\n",
      "Epoch 30/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8180 - loss: 0.3423 - val_accuracy: 0.8936 - val_loss: 0.2889\n",
      "Epoch 31/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8189 - loss: 0.3467 - val_accuracy: 0.8936 - val_loss: 0.2850\n",
      "Epoch 32/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8414 - loss: 0.3204 - val_accuracy: 0.8723 - val_loss: 0.2819\n",
      "Epoch 33/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.8479 - loss: 0.3507 - val_accuracy: 0.8936 - val_loss: 0.2793\n",
      "Epoch 34/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8638 - loss: 0.3181 - val_accuracy: 0.8936 - val_loss: 0.2779\n",
      "Epoch 35/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8795 - loss: 0.3258 - val_accuracy: 0.8723 - val_loss: 0.2802\n",
      "Epoch 36/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8481 - loss: 0.3355 - val_accuracy: 0.8936 - val_loss: 0.2760\n",
      "Epoch 37/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8605 - loss: 0.3165 - val_accuracy: 0.8723 - val_loss: 0.2715\n",
      "Epoch 38/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8474 - loss: 0.3233 - val_accuracy: 0.8936 - val_loss: 0.2713\n",
      "Epoch 39/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8667 - loss: 0.3245 - val_accuracy: 0.8511 - val_loss: 0.2707\n",
      "Epoch 40/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8671 - loss: 0.3052 - val_accuracy: 0.8936 - val_loss: 0.2651\n",
      "Epoch 41/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8271 - loss: 0.3657 - val_accuracy: 0.8723 - val_loss: 0.2643\n",
      "Epoch 42/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8397 - loss: 0.3320 - val_accuracy: 0.8936 - val_loss: 0.2668\n",
      "Epoch 43/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.8471 - loss: 0.3449 - val_accuracy: 0.8936 - val_loss: 0.2639\n",
      "Epoch 44/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8348 - loss: 0.3295 - val_accuracy: 0.8936 - val_loss: 0.2597\n",
      "Epoch 45/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8589 - loss: 0.3343 - val_accuracy: 0.8936 - val_loss: 0.2580\n",
      "Epoch 46/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8626 - loss: 0.3046 - val_accuracy: 0.8936 - val_loss: 0.2587\n",
      "Epoch 47/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8455 - loss: 0.3283 - val_accuracy: 0.8936 - val_loss: 0.2561\n",
      "Epoch 48/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8672 - loss: 0.3084 - val_accuracy: 0.8936 - val_loss: 0.2540\n",
      "Epoch 49/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8868 - loss: 0.2928 - val_accuracy: 0.8936 - val_loss: 0.2536\n",
      "Epoch 50/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8886 - loss: 0.2965 - val_accuracy: 0.8936 - val_loss: 0.2573\n",
      "Epoch 51/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8721 - loss: 0.2967 - val_accuracy: 0.8936 - val_loss: 0.2564\n",
      "Epoch 52/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8703 - loss: 0.2987 - val_accuracy: 0.8936 - val_loss: 0.2510\n",
      "Epoch 53/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8534 - loss: 0.3129 - val_accuracy: 0.8936 - val_loss: 0.2502\n",
      "Epoch 54/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8786 - loss: 0.2949 - val_accuracy: 0.8936 - val_loss: 0.2529\n",
      "Epoch 55/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9080 - loss: 0.2910 - val_accuracy: 0.8936 - val_loss: 0.2553\n",
      "Epoch 56/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8642 - loss: 0.3251 - val_accuracy: 0.8936 - val_loss: 0.2499\n",
      "Epoch 57/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8718 - loss: 0.2893 - val_accuracy: 0.8723 - val_loss: 0.2490\n",
      "Epoch 58/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8702 - loss: 0.2935 - val_accuracy: 0.8936 - val_loss: 0.2503\n",
      "Epoch 59/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8534 - loss: 0.3191 - val_accuracy: 0.8936 - val_loss: 0.2491\n",
      "Epoch 60/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8773 - loss: 0.2638 - val_accuracy: 0.8936 - val_loss: 0.2502\n",
      "Epoch 61/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8689 - loss: 0.2906 - val_accuracy: 0.8723 - val_loss: 0.2476\n",
      "Epoch 62/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8579 - loss: 0.2899 - val_accuracy: 0.8936 - val_loss: 0.2529\n",
      "Epoch 63/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8644 - loss: 0.3109 - val_accuracy: 0.8723 - val_loss: 0.2464\n",
      "Epoch 64/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8578 - loss: 0.2686 - val_accuracy: 0.8723 - val_loss: 0.2454\n",
      "Epoch 65/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8533 - loss: 0.3013 - val_accuracy: 0.8936 - val_loss: 0.2515\n",
      "Epoch 66/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8812 - loss: 0.2909 - val_accuracy: 0.8936 - val_loss: 0.2453\n",
      "Epoch 67/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8579 - loss: 0.3141 - val_accuracy: 0.8936 - val_loss: 0.2456\n",
      "Epoch 68/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8765 - loss: 0.2655 - val_accuracy: 0.8936 - val_loss: 0.2444\n",
      "Epoch 69/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8724 - loss: 0.3078 - val_accuracy: 0.8936 - val_loss: 0.2457\n",
      "Epoch 70/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8895 - loss: 0.2882 - val_accuracy: 0.8723 - val_loss: 0.2448\n",
      "Epoch 71/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8655 - loss: 0.2781 - val_accuracy: 0.8936 - val_loss: 0.2448\n",
      "Epoch 72/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8832 - loss: 0.3007 - val_accuracy: 0.8723 - val_loss: 0.2424\n",
      "Epoch 73/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8622 - loss: 0.3163 - val_accuracy: 0.8936 - val_loss: 0.2464\n",
      "Epoch 74/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8365 - loss: 0.3368 - val_accuracy: 0.8723 - val_loss: 0.2429\n",
      "Epoch 75/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8927 - loss: 0.2933 - val_accuracy: 0.8936 - val_loss: 0.2437\n",
      "Epoch 76/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8597 - loss: 0.3331 - val_accuracy: 0.8723 - val_loss: 0.2431\n",
      "Epoch 77/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8723 - loss: 0.2799 - val_accuracy: 0.8936 - val_loss: 0.2457\n",
      "Epoch 78/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8773 - loss: 0.2768 - val_accuracy: 0.8936 - val_loss: 0.2437\n",
      "Epoch 79/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8912 - loss: 0.2854 - val_accuracy: 0.8723 - val_loss: 0.2413\n",
      "Epoch 80/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8602 - loss: 0.2748 - val_accuracy: 0.8936 - val_loss: 0.2428\n",
      "Epoch 81/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8827 - loss: 0.2839 - val_accuracy: 0.8936 - val_loss: 0.2440\n",
      "Epoch 82/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8615 - loss: 0.3162 - val_accuracy: 0.8723 - val_loss: 0.2407\n",
      "Epoch 83/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8412 - loss: 0.3119 - val_accuracy: 0.8936 - val_loss: 0.2421\n",
      "Epoch 84/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8933 - loss: 0.2753 - val_accuracy: 0.8936 - val_loss: 0.2405\n",
      "Epoch 85/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8711 - loss: 0.2871 - val_accuracy: 0.8936 - val_loss: 0.2413\n",
      "Epoch 86/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8658 - loss: 0.2903 - val_accuracy: 0.8936 - val_loss: 0.2397\n",
      "Epoch 87/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8588 - loss: 0.3142 - val_accuracy: 0.8936 - val_loss: 0.2393\n",
      "Epoch 88/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8653 - loss: 0.2786 - val_accuracy: 0.8723 - val_loss: 0.2448\n",
      "Epoch 89/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8964 - loss: 0.2472 - val_accuracy: 0.8723 - val_loss: 0.2387\n",
      "Epoch 90/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8322 - loss: 0.3205 - val_accuracy: 0.8723 - val_loss: 0.2379\n",
      "Epoch 91/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8980 - loss: 0.2531 - val_accuracy: 0.8936 - val_loss: 0.2384\n",
      "Epoch 92/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8634 - loss: 0.2976 - val_accuracy: 0.8936 - val_loss: 0.2426\n",
      "Epoch 93/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8717 - loss: 0.2804 - val_accuracy: 0.8723 - val_loss: 0.2385\n",
      "Epoch 94/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8850 - loss: 0.2677 - val_accuracy: 0.8936 - val_loss: 0.2389\n",
      "Epoch 95/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8691 - loss: 0.2788 - val_accuracy: 0.8936 - val_loss: 0.2372\n",
      "Epoch 96/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9059 - loss: 0.2622 - val_accuracy: 0.8723 - val_loss: 0.2365\n",
      "Epoch 97/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8939 - loss: 0.2603 - val_accuracy: 0.8936 - val_loss: 0.2384\n",
      "Epoch 98/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8678 - loss: 0.3025 - val_accuracy: 0.8723 - val_loss: 0.2372\n",
      "Epoch 99/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8696 - loss: 0.2958 - val_accuracy: 0.8936 - val_loss: 0.2393\n",
      "Epoch 100/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8864 - loss: 0.2663 - val_accuracy: 0.8936 - val_loss: 0.2382\n",
      "Epoch 101/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8651 - loss: 0.2875 - val_accuracy: 0.8723 - val_loss: 0.2357\n",
      "Epoch 102/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8536 - loss: 0.2621 - val_accuracy: 0.8936 - val_loss: 0.2358\n",
      "Epoch 103/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8339 - loss: 0.3325 - val_accuracy: 0.8723 - val_loss: 0.2363\n",
      "Epoch 104/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8651 - loss: 0.2787 - val_accuracy: 0.8936 - val_loss: 0.2379\n",
      "Epoch 105/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8939 - loss: 0.2971 - val_accuracy: 0.8723 - val_loss: 0.2351\n",
      "Epoch 106/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8624 - loss: 0.2869 - val_accuracy: 0.8723 - val_loss: 0.2348\n",
      "Epoch 107/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8770 - loss: 0.2780 - val_accuracy: 0.8936 - val_loss: 0.2358\n",
      "Epoch 108/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8598 - loss: 0.3066 - val_accuracy: 0.8511 - val_loss: 0.2409\n",
      "Epoch 109/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8615 - loss: 0.3065 - val_accuracy: 0.8723 - val_loss: 0.2367\n",
      "Epoch 110/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8612 - loss: 0.2747 - val_accuracy: 0.8723 - val_loss: 0.2364\n",
      "Epoch 111/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8772 - loss: 0.3032 - val_accuracy: 0.8298 - val_loss: 0.2455\n",
      "Epoch 112/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8657 - loss: 0.2716 - val_accuracy: 0.8723 - val_loss: 0.2351\n",
      "Epoch 113/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8625 - loss: 0.2803 - val_accuracy: 0.8723 - val_loss: 0.2371\n",
      "Epoch 114/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8709 - loss: 0.2535 - val_accuracy: 0.8936 - val_loss: 0.2353\n",
      "Epoch 115/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8308 - loss: 0.3051 - val_accuracy: 0.8511 - val_loss: 0.2377\n",
      "Epoch 116/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8872 - loss: 0.2709 - val_accuracy: 0.8723 - val_loss: 0.2343\n",
      "Epoch 117/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8822 - loss: 0.2554 - val_accuracy: 0.8723 - val_loss: 0.2343\n",
      "Epoch 118/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8793 - loss: 0.2637 - val_accuracy: 0.8936 - val_loss: 0.2355\n",
      "Epoch 119/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8674 - loss: 0.2946 - val_accuracy: 0.8723 - val_loss: 0.2337\n",
      "Epoch 120/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8907 - loss: 0.2407 - val_accuracy: 0.8723 - val_loss: 0.2343\n",
      "Epoch 121/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8839 - loss: 0.2629 - val_accuracy: 0.8723 - val_loss: 0.2344\n",
      "Epoch 122/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8910 - loss: 0.2735 - val_accuracy: 0.8936 - val_loss: 0.2352\n",
      "Epoch 123/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9040 - loss: 0.2471 - val_accuracy: 0.8936 - val_loss: 0.2336\n",
      "Epoch 124/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8509 - loss: 0.3103 - val_accuracy: 0.8723 - val_loss: 0.2319\n",
      "Epoch 125/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8931 - loss: 0.2604 - val_accuracy: 0.8936 - val_loss: 0.2329\n",
      "Epoch 126/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9192 - loss: 0.2474 - val_accuracy: 0.8723 - val_loss: 0.2355\n",
      "Epoch 127/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8564 - loss: 0.2751 - val_accuracy: 0.8723 - val_loss: 0.2349\n",
      "Epoch 128/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8985 - loss: 0.2632 - val_accuracy: 0.8936 - val_loss: 0.2337\n",
      "Epoch 129/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8688 - loss: 0.2823 - val_accuracy: 0.8511 - val_loss: 0.2364\n",
      "Epoch 130/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8728 - loss: 0.2788 - val_accuracy: 0.8723 - val_loss: 0.2338\n",
      "Epoch 131/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8878 - loss: 0.2791 - val_accuracy: 0.8723 - val_loss: 0.2326\n",
      "Epoch 132/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8953 - loss: 0.2658 - val_accuracy: 0.8511 - val_loss: 0.2358\n",
      "Epoch 133/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8627 - loss: 0.2950 - val_accuracy: 0.8723 - val_loss: 0.2333\n",
      "Epoch 134/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8747 - loss: 0.2467 - val_accuracy: 0.8936 - val_loss: 0.2332\n",
      "Epoch 135/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8656 - loss: 0.2945 - val_accuracy: 0.8936 - val_loss: 0.2331\n",
      "Epoch 136/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8604 - loss: 0.3078 - val_accuracy: 0.8936 - val_loss: 0.2326\n",
      "Epoch 137/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8907 - loss: 0.2643 - val_accuracy: 0.8723 - val_loss: 0.2320\n",
      "Epoch 138/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8822 - loss: 0.2686 - val_accuracy: 0.8723 - val_loss: 0.2314\n",
      "Epoch 139/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8722 - loss: 0.2535 - val_accuracy: 0.8298 - val_loss: 0.2381\n",
      "Epoch 140/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.8759 - loss: 0.2768 - val_accuracy: 0.8723 - val_loss: 0.2330\n",
      "Epoch 141/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8651 - loss: 0.2931 - val_accuracy: 0.8723 - val_loss: 0.2338\n",
      "Epoch 142/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8776 - loss: 0.2803 - val_accuracy: 0.8936 - val_loss: 0.2333\n",
      "Epoch 143/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8886 - loss: 0.2554 - val_accuracy: 0.8723 - val_loss: 0.2321\n",
      "Epoch 144/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8665 - loss: 0.2878 - val_accuracy: 0.8723 - val_loss: 0.2318\n",
      "Epoch 145/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8638 - loss: 0.2828 - val_accuracy: 0.8723 - val_loss: 0.2338\n",
      "Epoch 146/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8914 - loss: 0.2630 - val_accuracy: 0.8723 - val_loss: 0.2349\n",
      "Epoch 147/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9014 - loss: 0.2629 - val_accuracy: 0.8298 - val_loss: 0.2407\n",
      "Epoch 148/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8980 - loss: 0.2403 - val_accuracy: 0.8511 - val_loss: 0.2360\n",
      "Epoch 149/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8904 - loss: 0.2593 - val_accuracy: 0.8723 - val_loss: 0.2317\n",
      "Epoch 150/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8586 - loss: 0.2781 - val_accuracy: 0.8723 - val_loss: 0.2337\n",
      "Epoch 151/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8617 - loss: 0.2786 - val_accuracy: 0.8723 - val_loss: 0.2310\n",
      "Epoch 152/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.8789 - loss: 0.2627 - val_accuracy: 0.8723 - val_loss: 0.2321\n",
      "Epoch 153/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8754 - loss: 0.2423 - val_accuracy: 0.8723 - val_loss: 0.2311\n",
      "Epoch 154/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8773 - loss: 0.2810 - val_accuracy: 0.8723 - val_loss: 0.2330\n",
      "Epoch 155/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8874 - loss: 0.2569 - val_accuracy: 0.8723 - val_loss: 0.2326\n",
      "Epoch 156/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.8827 - loss: 0.2653 - val_accuracy: 0.8723 - val_loss: 0.2319\n",
      "Epoch 157/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8865 - loss: 0.2642 - val_accuracy: 0.8723 - val_loss: 0.2318\n",
      "Epoch 158/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8764 - loss: 0.2623 - val_accuracy: 0.8723 - val_loss: 0.2324\n",
      "Epoch 159/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8965 - loss: 0.2439 - val_accuracy: 0.8511 - val_loss: 0.2368\n",
      "Epoch 160/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8340 - loss: 0.3100 - val_accuracy: 0.8723 - val_loss: 0.2331\n",
      "Epoch 161/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8549 - loss: 0.2678 - val_accuracy: 0.8723 - val_loss: 0.2318\n",
      "Epoch 162/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8855 - loss: 0.2609 - val_accuracy: 0.8936 - val_loss: 0.2316\n",
      "Epoch 163/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8781 - loss: 0.2758 - val_accuracy: 0.8723 - val_loss: 0.2316\n",
      "Epoch 164/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8899 - loss: 0.2679 - val_accuracy: 0.8723 - val_loss: 0.2321\n",
      "Epoch 165/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8626 - loss: 0.2688 - val_accuracy: 0.8511 - val_loss: 0.2364\n",
      "Epoch 166/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8454 - loss: 0.2975 - val_accuracy: 0.8723 - val_loss: 0.2343\n",
      "Epoch 167/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8899 - loss: 0.2425 - val_accuracy: 0.8723 - val_loss: 0.2335\n",
      "Epoch 168/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8836 - loss: 0.2473 - val_accuracy: 0.8723 - val_loss: 0.2334\n",
      "Epoch 169/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8794 - loss: 0.2520 - val_accuracy: 0.8723 - val_loss: 0.2332\n",
      "Epoch 170/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8447 - loss: 0.2845 - val_accuracy: 0.8723 - val_loss: 0.2350\n",
      "Epoch 171/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8706 - loss: 0.2894 - val_accuracy: 0.8936 - val_loss: 0.2371\n",
      "Epoch 172/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8621 - loss: 0.2734 - val_accuracy: 0.8723 - val_loss: 0.2333\n",
      "Epoch 173/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9008 - loss: 0.2439 - val_accuracy: 0.8723 - val_loss: 0.2332\n",
      "Epoch 174/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8875 - loss: 0.2601 - val_accuracy: 0.8723 - val_loss: 0.2330\n",
      "Epoch 175/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.8880 - loss: 0.2582 - val_accuracy: 0.8723 - val_loss: 0.2325\n",
      "Epoch 176/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8884 - loss: 0.2484 - val_accuracy: 0.8936 - val_loss: 0.2340\n",
      "Epoch 177/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8664 - loss: 0.2939 - val_accuracy: 0.8723 - val_loss: 0.2329\n",
      "Epoch 178/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8768 - loss: 0.2487 - val_accuracy: 0.8936 - val_loss: 0.2329\n",
      "Epoch 179/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8851 - loss: 0.2608 - val_accuracy: 0.8936 - val_loss: 0.2348\n",
      "Epoch 180/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8582 - loss: 0.2802 - val_accuracy: 0.8936 - val_loss: 0.2364\n",
      "Epoch 181/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8349 - loss: 0.3109 - val_accuracy: 0.8723 - val_loss: 0.2363\n",
      "Epoch 182/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8527 - loss: 0.2920 - val_accuracy: 0.8723 - val_loss: 0.2337\n",
      "Epoch 183/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8838 - loss: 0.2599 - val_accuracy: 0.8723 - val_loss: 0.2336\n",
      "Epoch 184/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9025 - loss: 0.2424 - val_accuracy: 0.8511 - val_loss: 0.2356\n",
      "Epoch 185/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8537 - loss: 0.3018 - val_accuracy: 0.8723 - val_loss: 0.2371\n",
      "Epoch 186/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8597 - loss: 0.2911 - val_accuracy: 0.8723 - val_loss: 0.2353\n",
      "Epoch 187/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.8999 - loss: 0.2145 - val_accuracy: 0.8723 - val_loss: 0.2355\n",
      "Epoch 188/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8716 - loss: 0.2702 - val_accuracy: 0.8511 - val_loss: 0.2369\n",
      "Epoch 189/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8978 - loss: 0.2337 - val_accuracy: 0.8723 - val_loss: 0.2372\n",
      "Epoch 190/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8917 - loss: 0.2457 - val_accuracy: 0.8723 - val_loss: 0.2342\n",
      "Epoch 191/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8805 - loss: 0.2441 - val_accuracy: 0.8723 - val_loss: 0.2351\n",
      "Epoch 192/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8690 - loss: 0.2623 - val_accuracy: 0.8723 - val_loss: 0.2359\n",
      "Epoch 193/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8851 - loss: 0.2536 - val_accuracy: 0.8723 - val_loss: 0.2358\n",
      "Epoch 194/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8883 - loss: 0.2681 - val_accuracy: 0.8723 - val_loss: 0.2355\n",
      "Epoch 195/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8686 - loss: 0.2458 - val_accuracy: 0.8936 - val_loss: 0.2378\n",
      "Epoch 196/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8702 - loss: 0.2518 - val_accuracy: 0.8723 - val_loss: 0.2347\n",
      "Epoch 197/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8839 - loss: 0.2618 - val_accuracy: 0.8723 - val_loss: 0.2354\n",
      "Epoch 198/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9089 - loss: 0.2467 - val_accuracy: 0.8936 - val_loss: 0.2366\n",
      "Epoch 199/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8950 - loss: 0.2599 - val_accuracy: 0.8511 - val_loss: 0.2360\n",
      "Epoch 200/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9008 - loss: 0.2382 - val_accuracy: 0.8936 - val_loss: 0.2375\n",
      "Epoch 201/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9001 - loss: 0.2441 - val_accuracy: 0.8723 - val_loss: 0.2356\n",
      "Epoch 202/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8926 - loss: 0.2472 - val_accuracy: 0.8723 - val_loss: 0.2363\n",
      "Epoch 203/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8999 - loss: 0.2181 - val_accuracy: 0.8723 - val_loss: 0.2391\n",
      "Epoch 204/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8527 - loss: 0.2810 - val_accuracy: 0.8511 - val_loss: 0.2361\n",
      "Epoch 205/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8992 - loss: 0.2524 - val_accuracy: 0.8723 - val_loss: 0.2347\n",
      "Epoch 206/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8988 - loss: 0.2548 - val_accuracy: 0.8936 - val_loss: 0.2378\n",
      "Epoch 207/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8683 - loss: 0.2460 - val_accuracy: 0.8511 - val_loss: 0.2395\n",
      "Epoch 208/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8799 - loss: 0.2592 - val_accuracy: 0.8723 - val_loss: 0.2404\n",
      "Epoch 209/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8831 - loss: 0.2799 - val_accuracy: 0.8936 - val_loss: 0.2395\n",
      "Epoch 210/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8715 - loss: 0.2571 - val_accuracy: 0.8511 - val_loss: 0.2363\n",
      "Epoch 211/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8897 - loss: 0.2564 - val_accuracy: 0.8511 - val_loss: 0.2360\n",
      "Epoch 212/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8990 - loss: 0.2445 - val_accuracy: 0.8723 - val_loss: 0.2377\n",
      "Epoch 213/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8731 - loss: 0.2574 - val_accuracy: 0.8936 - val_loss: 0.2420\n",
      "Epoch 214/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8713 - loss: 0.2521 - val_accuracy: 0.8511 - val_loss: 0.2395\n",
      "Epoch 215/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9020 - loss: 0.2612 - val_accuracy: 0.8936 - val_loss: 0.2416\n",
      "Epoch 216/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8791 - loss: 0.2541 - val_accuracy: 0.8511 - val_loss: 0.2405\n",
      "Epoch 217/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8944 - loss: 0.2443 - val_accuracy: 0.8936 - val_loss: 0.2410\n",
      "Epoch 218/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8912 - loss: 0.2686 - val_accuracy: 0.8511 - val_loss: 0.2399\n",
      "Epoch 219/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9010 - loss: 0.2822 - val_accuracy: 0.8723 - val_loss: 0.2453\n",
      "Epoch 220/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8980 - loss: 0.2391 - val_accuracy: 0.8723 - val_loss: 0.2391\n",
      "Epoch 221/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8809 - loss: 0.2496 - val_accuracy: 0.8511 - val_loss: 0.2412\n",
      "Epoch 222/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8872 - loss: 0.2575 - val_accuracy: 0.8936 - val_loss: 0.2399\n",
      "Epoch 223/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9037 - loss: 0.2639 - val_accuracy: 0.8936 - val_loss: 0.2412\n",
      "Epoch 224/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9083 - loss: 0.2432 - val_accuracy: 0.8511 - val_loss: 0.2396\n",
      "Epoch 225/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8848 - loss: 0.2506 - val_accuracy: 0.8723 - val_loss: 0.2393\n",
      "Epoch 226/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8676 - loss: 0.2695 - val_accuracy: 0.8936 - val_loss: 0.2421\n",
      "Epoch 227/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8644 - loss: 0.2592 - val_accuracy: 0.8723 - val_loss: 0.2407\n",
      "Epoch 228/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8810 - loss: 0.2634 - val_accuracy: 0.8936 - val_loss: 0.2429\n",
      "Epoch 229/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8727 - loss: 0.2715 - val_accuracy: 0.8511 - val_loss: 0.2410\n",
      "Epoch 230/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8836 - loss: 0.2431 - val_accuracy: 0.8936 - val_loss: 0.2424\n",
      "Epoch 231/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8763 - loss: 0.2367 - val_accuracy: 0.8511 - val_loss: 0.2405\n",
      "Epoch 232/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8797 - loss: 0.2678 - val_accuracy: 0.8511 - val_loss: 0.2405\n",
      "Epoch 233/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8812 - loss: 0.2425 - val_accuracy: 0.8511 - val_loss: 0.2415\n",
      "Epoch 234/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8518 - loss: 0.2712 - val_accuracy: 0.8936 - val_loss: 0.2424\n",
      "Epoch 235/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8888 - loss: 0.2581 - val_accuracy: 0.8511 - val_loss: 0.2396\n",
      "Epoch 236/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8682 - loss: 0.2481 - val_accuracy: 0.8723 - val_loss: 0.2405\n",
      "Epoch 237/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8939 - loss: 0.2201 - val_accuracy: 0.8723 - val_loss: 0.2419\n",
      "Epoch 238/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8802 - loss: 0.2477 - val_accuracy: 0.8723 - val_loss: 0.2412\n",
      "Epoch 239/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8814 - loss: 0.2370 - val_accuracy: 0.8936 - val_loss: 0.2430\n",
      "Epoch 240/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8681 - loss: 0.2500 - val_accuracy: 0.8511 - val_loss: 0.2420\n",
      "Epoch 241/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8939 - loss: 0.2660 - val_accuracy: 0.8723 - val_loss: 0.2424\n",
      "Epoch 242/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8469 - loss: 0.2739 - val_accuracy: 0.8936 - val_loss: 0.2462\n",
      "Epoch 243/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8767 - loss: 0.2526 - val_accuracy: 0.8511 - val_loss: 0.2451\n",
      "Epoch 244/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8857 - loss: 0.2720 - val_accuracy: 0.8723 - val_loss: 0.2469\n",
      "Epoch 245/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8858 - loss: 0.2322 - val_accuracy: 0.8511 - val_loss: 0.2430\n",
      "Epoch 246/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8832 - loss: 0.2687 - val_accuracy: 0.8511 - val_loss: 0.2428\n",
      "Epoch 247/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8864 - loss: 0.2472 - val_accuracy: 0.8936 - val_loss: 0.2458\n",
      "Epoch 248/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8840 - loss: 0.2674 - val_accuracy: 0.8511 - val_loss: 0.2437\n",
      "Epoch 249/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9267 - loss: 0.2238 - val_accuracy: 0.8936 - val_loss: 0.2447\n",
      "Epoch 250/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8666 - loss: 0.2507 - val_accuracy: 0.8511 - val_loss: 0.2436\n",
      "Epoch 251/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8944 - loss: 0.2318 - val_accuracy: 0.8723 - val_loss: 0.2440\n",
      "Epoch 252/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8779 - loss: 0.2429 - val_accuracy: 0.8936 - val_loss: 0.2464\n",
      "Epoch 253/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8720 - loss: 0.2442 - val_accuracy: 0.8511 - val_loss: 0.2436\n",
      "Epoch 254/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8639 - loss: 0.2596 - val_accuracy: 0.8723 - val_loss: 0.2480\n",
      "Epoch 255/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8607 - loss: 0.2690 - val_accuracy: 0.8298 - val_loss: 0.2512\n",
      "Epoch 256/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8779 - loss: 0.2602 - val_accuracy: 0.8723 - val_loss: 0.2568\n",
      "Epoch 257/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8821 - loss: 0.2716 - val_accuracy: 0.8511 - val_loss: 0.2453\n",
      "Epoch 258/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8966 - loss: 0.2445 - val_accuracy: 0.8511 - val_loss: 0.2440\n",
      "Epoch 259/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8637 - loss: 0.2862 - val_accuracy: 0.8723 - val_loss: 0.2494\n",
      "Epoch 260/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8781 - loss: 0.2833 - val_accuracy: 0.8936 - val_loss: 0.2484\n",
      "Epoch 261/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9160 - loss: 0.2238 - val_accuracy: 0.8511 - val_loss: 0.2477\n",
      "Epoch 262/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8653 - loss: 0.2657 - val_accuracy: 0.8936 - val_loss: 0.2502\n",
      "Epoch 263/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9169 - loss: 0.2392 - val_accuracy: 0.8723 - val_loss: 0.2525\n",
      "Epoch 264/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8897 - loss: 0.2377 - val_accuracy: 0.8511 - val_loss: 0.2478\n",
      "Epoch 265/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8869 - loss: 0.2550 - val_accuracy: 0.8511 - val_loss: 0.2489\n",
      "Epoch 266/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8787 - loss: 0.2607 - val_accuracy: 0.8723 - val_loss: 0.2568\n",
      "Epoch 267/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8863 - loss: 0.2557 - val_accuracy: 0.8723 - val_loss: 0.2478\n",
      "Epoch 268/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8924 - loss: 0.2518 - val_accuracy: 0.8936 - val_loss: 0.2495\n",
      "Epoch 269/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8783 - loss: 0.2644 - val_accuracy: 0.8936 - val_loss: 0.2513\n",
      "Epoch 270/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8883 - loss: 0.2440 - val_accuracy: 0.8723 - val_loss: 0.2495\n",
      "Epoch 271/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8798 - loss: 0.2356 - val_accuracy: 0.8511 - val_loss: 0.2498\n",
      "Epoch 272/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8847 - loss: 0.2506 - val_accuracy: 0.8723 - val_loss: 0.2596\n",
      "Epoch 273/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8826 - loss: 0.2643 - val_accuracy: 0.8511 - val_loss: 0.2512\n",
      "Epoch 274/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9039 - loss: 0.2228 - val_accuracy: 0.8936 - val_loss: 0.2531\n",
      "Epoch 275/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8895 - loss: 0.2416 - val_accuracy: 0.8723 - val_loss: 0.2499\n",
      "Epoch 276/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8822 - loss: 0.2346 - val_accuracy: 0.8723 - val_loss: 0.2540\n",
      "Epoch 277/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9071 - loss: 0.2155 - val_accuracy: 0.8723 - val_loss: 0.2497\n",
      "Epoch 278/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8692 - loss: 0.2641 - val_accuracy: 0.8511 - val_loss: 0.2507\n",
      "Epoch 279/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8794 - loss: 0.2579 - val_accuracy: 0.8723 - val_loss: 0.2560\n",
      "Epoch 280/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8846 - loss: 0.2551 - val_accuracy: 0.8511 - val_loss: 0.2498\n",
      "Epoch 281/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8649 - loss: 0.2704 - val_accuracy: 0.8936 - val_loss: 0.2537\n",
      "Epoch 282/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8810 - loss: 0.2459 - val_accuracy: 0.8936 - val_loss: 0.2535\n",
      "Epoch 283/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8971 - loss: 0.2268 - val_accuracy: 0.8723 - val_loss: 0.2513\n",
      "Epoch 284/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8838 - loss: 0.2426 - val_accuracy: 0.8511 - val_loss: 0.2518\n",
      "Epoch 285/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8784 - loss: 0.2592 - val_accuracy: 0.8723 - val_loss: 0.2580\n",
      "Epoch 286/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8586 - loss: 0.2544 - val_accuracy: 0.8723 - val_loss: 0.2546\n",
      "Epoch 287/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8759 - loss: 0.2610 - val_accuracy: 0.8723 - val_loss: 0.2526\n",
      "Epoch 288/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8460 - loss: 0.3025 - val_accuracy: 0.8936 - val_loss: 0.2560\n",
      "Epoch 289/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8920 - loss: 0.2265 - val_accuracy: 0.8511 - val_loss: 0.2554\n",
      "Epoch 290/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8793 - loss: 0.2444 - val_accuracy: 0.8723 - val_loss: 0.2552\n",
      "Epoch 291/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.8563 - loss: 0.2815 - val_accuracy: 0.8723 - val_loss: 0.2577\n",
      "Epoch 292/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9119 - loss: 0.2142 - val_accuracy: 0.8511 - val_loss: 0.2543\n",
      "Epoch 293/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8906 - loss: 0.2475 - val_accuracy: 0.8936 - val_loss: 0.2552\n",
      "Epoch 294/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8784 - loss: 0.2451 - val_accuracy: 0.8936 - val_loss: 0.2561\n",
      "Epoch 295/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8664 - loss: 0.2721 - val_accuracy: 0.8723 - val_loss: 0.2548\n",
      "Epoch 296/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9177 - loss: 0.2107 - val_accuracy: 0.8936 - val_loss: 0.2561\n",
      "Epoch 297/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.8960 - loss: 0.2268 - val_accuracy: 0.8511 - val_loss: 0.2536\n",
      "Epoch 298/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9137 - loss: 0.2234 - val_accuracy: 0.8723 - val_loss: 0.2594\n",
      "Epoch 299/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9093 - loss: 0.2201 - val_accuracy: 0.8511 - val_loss: 0.2548\n",
      "Epoch 300/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8730 - loss: 0.2569 - val_accuracy: 0.8723 - val_loss: 0.2594\n",
      "Epoch 301/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8874 - loss: 0.2265 - val_accuracy: 0.8511 - val_loss: 0.2558\n",
      "Epoch 302/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8924 - loss: 0.2456 - val_accuracy: 0.8723 - val_loss: 0.2551\n",
      "Epoch 303/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9206 - loss: 0.2388 - val_accuracy: 0.8723 - val_loss: 0.2580\n",
      "Epoch 304/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9206 - loss: 0.2099 - val_accuracy: 0.8511 - val_loss: 0.2550\n",
      "Epoch 305/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8960 - loss: 0.2253 - val_accuracy: 0.8936 - val_loss: 0.2578\n",
      "Epoch 306/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9054 - loss: 0.2312 - val_accuracy: 0.8936 - val_loss: 0.2599\n",
      "Epoch 307/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8733 - loss: 0.2350 - val_accuracy: 0.8511 - val_loss: 0.2558\n",
      "Epoch 308/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8940 - loss: 0.2396 - val_accuracy: 0.8723 - val_loss: 0.2587\n",
      "Epoch 309/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8701 - loss: 0.2471 - val_accuracy: 0.8723 - val_loss: 0.2590\n",
      "Epoch 310/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8755 - loss: 0.2615 - val_accuracy: 0.8936 - val_loss: 0.2596\n",
      "Epoch 311/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9019 - loss: 0.2166 - val_accuracy: 0.8511 - val_loss: 0.2587\n",
      "Epoch 312/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.8882 - loss: 0.2374 - val_accuracy: 0.8723 - val_loss: 0.2611\n",
      "Epoch 313/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8936 - loss: 0.2343 - val_accuracy: 0.8723 - val_loss: 0.2593\n",
      "Epoch 314/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8805 - loss: 0.2594 - val_accuracy: 0.8723 - val_loss: 0.2583\n",
      "Epoch 315/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9297 - loss: 0.1932 - val_accuracy: 0.8511 - val_loss: 0.2574\n",
      "Epoch 316/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9080 - loss: 0.2308 - val_accuracy: 0.8723 - val_loss: 0.2613\n",
      "Epoch 317/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9232 - loss: 0.2014 - val_accuracy: 0.8723 - val_loss: 0.2565\n",
      "Epoch 318/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9053 - loss: 0.2185 - val_accuracy: 0.8511 - val_loss: 0.2585\n",
      "Epoch 319/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9205 - loss: 0.2165 - val_accuracy: 0.8723 - val_loss: 0.2689\n",
      "Epoch 320/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8900 - loss: 0.2480 - val_accuracy: 0.8723 - val_loss: 0.2573\n",
      "Epoch 321/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8891 - loss: 0.2381 - val_accuracy: 0.8723 - val_loss: 0.2596\n",
      "Epoch 322/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8869 - loss: 0.2361 - val_accuracy: 0.8723 - val_loss: 0.2612\n",
      "Epoch 323/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9119 - loss: 0.2067 - val_accuracy: 0.8723 - val_loss: 0.2614\n",
      "Epoch 324/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9150 - loss: 0.2156 - val_accuracy: 0.8723 - val_loss: 0.2598\n",
      "Epoch 325/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8818 - loss: 0.2522 - val_accuracy: 0.8723 - val_loss: 0.2608\n",
      "Epoch 326/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8921 - loss: 0.2329 - val_accuracy: 0.8723 - val_loss: 0.2591\n",
      "Epoch 327/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8998 - loss: 0.2203 - val_accuracy: 0.8723 - val_loss: 0.2602\n",
      "Epoch 328/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8835 - loss: 0.2283 - val_accuracy: 0.8723 - val_loss: 0.2707\n",
      "Epoch 329/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8950 - loss: 0.2517 - val_accuracy: 0.8723 - val_loss: 0.2599\n",
      "Epoch 330/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8650 - loss: 0.2668 - val_accuracy: 0.8511 - val_loss: 0.2594\n",
      "Epoch 331/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8961 - loss: 0.2206 - val_accuracy: 0.8723 - val_loss: 0.2660\n",
      "Epoch 332/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8967 - loss: 0.2434 - val_accuracy: 0.8723 - val_loss: 0.2693\n",
      "Epoch 333/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9062 - loss: 0.2244 - val_accuracy: 0.8298 - val_loss: 0.2625\n",
      "Epoch 334/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9108 - loss: 0.2263 - val_accuracy: 0.8723 - val_loss: 0.2611\n",
      "Epoch 335/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9204 - loss: 0.1916 - val_accuracy: 0.8723 - val_loss: 0.2690\n",
      "Epoch 336/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8997 - loss: 0.2196 - val_accuracy: 0.8723 - val_loss: 0.2623\n",
      "Epoch 337/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9089 - loss: 0.2212 - val_accuracy: 0.8723 - val_loss: 0.2650\n",
      "Epoch 338/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8931 - loss: 0.2336 - val_accuracy: 0.8723 - val_loss: 0.2688\n",
      "Epoch 339/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8963 - loss: 0.2242 - val_accuracy: 0.8723 - val_loss: 0.2595\n",
      "Epoch 340/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9156 - loss: 0.2096 - val_accuracy: 0.8723 - val_loss: 0.2612\n",
      "Epoch 341/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8866 - loss: 0.2257 - val_accuracy: 0.8723 - val_loss: 0.2675\n",
      "Epoch 342/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8858 - loss: 0.2336 - val_accuracy: 0.8723 - val_loss: 0.2637\n",
      "Epoch 343/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9093 - loss: 0.2150 - val_accuracy: 0.8723 - val_loss: 0.2631\n",
      "Epoch 344/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9145 - loss: 0.2222 - val_accuracy: 0.8723 - val_loss: 0.2743\n",
      "Epoch 345/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9004 - loss: 0.2229 - val_accuracy: 0.8723 - val_loss: 0.2625\n",
      "Epoch 346/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8687 - loss: 0.2685 - val_accuracy: 0.8936 - val_loss: 0.2661\n",
      "Epoch 347/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8837 - loss: 0.2428 - val_accuracy: 0.8723 - val_loss: 0.2638\n",
      "Epoch 348/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8974 - loss: 0.2267 - val_accuracy: 0.8723 - val_loss: 0.2723\n",
      "Epoch 349/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8832 - loss: 0.2612 - val_accuracy: 0.8723 - val_loss: 0.2638\n",
      "Epoch 350/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9040 - loss: 0.2493 - val_accuracy: 0.8723 - val_loss: 0.2657\n",
      "Epoch 351/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8884 - loss: 0.2195 - val_accuracy: 0.8936 - val_loss: 0.2664\n",
      "Epoch 352/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9120 - loss: 0.2212 - val_accuracy: 0.8511 - val_loss: 0.2652\n",
      "Epoch 353/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8948 - loss: 0.2394 - val_accuracy: 0.8723 - val_loss: 0.2673\n",
      "Epoch 354/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9065 - loss: 0.2128 - val_accuracy: 0.8723 - val_loss: 0.2676\n",
      "Epoch 355/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9095 - loss: 0.2209 - val_accuracy: 0.8723 - val_loss: 0.2672\n",
      "Epoch 356/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8809 - loss: 0.2321 - val_accuracy: 0.8723 - val_loss: 0.2663\n",
      "Epoch 357/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9087 - loss: 0.2355 - val_accuracy: 0.8936 - val_loss: 0.2693\n",
      "Epoch 358/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9104 - loss: 0.2184 - val_accuracy: 0.8723 - val_loss: 0.2657\n",
      "Epoch 359/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9174 - loss: 0.2144 - val_accuracy: 0.8723 - val_loss: 0.2675\n",
      "Epoch 360/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9049 - loss: 0.2307 - val_accuracy: 0.8936 - val_loss: 0.2685\n",
      "Epoch 361/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8932 - loss: 0.2359 - val_accuracy: 0.8723 - val_loss: 0.2664\n",
      "Epoch 362/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8770 - loss: 0.2394 - val_accuracy: 0.8936 - val_loss: 0.2701\n",
      "Epoch 363/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8932 - loss: 0.2305 - val_accuracy: 0.8936 - val_loss: 0.2709\n",
      "Epoch 364/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9128 - loss: 0.2077 - val_accuracy: 0.8723 - val_loss: 0.2664\n",
      "Epoch 365/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8677 - loss: 0.2468 - val_accuracy: 0.8936 - val_loss: 0.2710\n",
      "Epoch 366/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9001 - loss: 0.2258 - val_accuracy: 0.8936 - val_loss: 0.2731\n",
      "Epoch 367/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9284 - loss: 0.1935 - val_accuracy: 0.8723 - val_loss: 0.2678\n",
      "Epoch 368/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9318 - loss: 0.1887 - val_accuracy: 0.8723 - val_loss: 0.2728\n",
      "Epoch 369/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9003 - loss: 0.2189 - val_accuracy: 0.8723 - val_loss: 0.2690\n",
      "Epoch 370/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8966 - loss: 0.2217 - val_accuracy: 0.8723 - val_loss: 0.2694\n",
      "Epoch 371/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8661 - loss: 0.2404 - val_accuracy: 0.8511 - val_loss: 0.2712\n",
      "Epoch 372/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8933 - loss: 0.2357 - val_accuracy: 0.8723 - val_loss: 0.2746\n",
      "Epoch 373/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8920 - loss: 0.2366 - val_accuracy: 0.8723 - val_loss: 0.2712\n",
      "Epoch 374/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9013 - loss: 0.2089 - val_accuracy: 0.8723 - val_loss: 0.2699\n",
      "Epoch 375/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8697 - loss: 0.2669 - val_accuracy: 0.8936 - val_loss: 0.2719\n",
      "Epoch 376/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8674 - loss: 0.2409 - val_accuracy: 0.8511 - val_loss: 0.2722\n",
      "Epoch 377/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8907 - loss: 0.2389 - val_accuracy: 0.8936 - val_loss: 0.2764\n",
      "Epoch 378/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9203 - loss: 0.2256 - val_accuracy: 0.8723 - val_loss: 0.2816\n",
      "Epoch 379/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8947 - loss: 0.2350 - val_accuracy: 0.8298 - val_loss: 0.2734\n",
      "Epoch 380/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9141 - loss: 0.2239 - val_accuracy: 0.8723 - val_loss: 0.2742\n",
      "Epoch 381/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8684 - loss: 0.2492 - val_accuracy: 0.8723 - val_loss: 0.2804\n",
      "Epoch 382/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9118 - loss: 0.2248 - val_accuracy: 0.8723 - val_loss: 0.2702\n",
      "Epoch 383/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8895 - loss: 0.2426 - val_accuracy: 0.8511 - val_loss: 0.2735\n",
      "Epoch 384/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8838 - loss: 0.2165 - val_accuracy: 0.8723 - val_loss: 0.2822\n",
      "Epoch 385/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9193 - loss: 0.2284 - val_accuracy: 0.8723 - val_loss: 0.2739\n",
      "Epoch 386/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9110 - loss: 0.2121 - val_accuracy: 0.8723 - val_loss: 0.2720\n",
      "Epoch 387/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8962 - loss: 0.2434 - val_accuracy: 0.8723 - val_loss: 0.2827\n",
      "Epoch 388/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8916 - loss: 0.2654 - val_accuracy: 0.8511 - val_loss: 0.2745\n",
      "Epoch 389/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8890 - loss: 0.2124 - val_accuracy: 0.8723 - val_loss: 0.2769\n",
      "Epoch 390/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8924 - loss: 0.2350 - val_accuracy: 0.8936 - val_loss: 0.2790\n",
      "Epoch 391/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8960 - loss: 0.2184 - val_accuracy: 0.8511 - val_loss: 0.2722\n",
      "Epoch 392/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8865 - loss: 0.2462 - val_accuracy: 0.8936 - val_loss: 0.2808\n",
      "Epoch 393/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8822 - loss: 0.2522 - val_accuracy: 0.8511 - val_loss: 0.2750\n",
      "Epoch 394/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8787 - loss: 0.2262 - val_accuracy: 0.8723 - val_loss: 0.2827\n",
      "Epoch 395/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9240 - loss: 0.1897 - val_accuracy: 0.8936 - val_loss: 0.2787\n",
      "Epoch 396/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9096 - loss: 0.2131 - val_accuracy: 0.8511 - val_loss: 0.2754\n",
      "Epoch 397/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9147 - loss: 0.2168 - val_accuracy: 0.8723 - val_loss: 0.2897\n",
      "Epoch 398/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9263 - loss: 0.2271 - val_accuracy: 0.8511 - val_loss: 0.2739\n",
      "Epoch 399/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8736 - loss: 0.2398 - val_accuracy: 0.8511 - val_loss: 0.2775\n",
      "Epoch 400/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8903 - loss: 0.2397 - val_accuracy: 0.8511 - val_loss: 0.2796\n",
      "Epoch 401/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9335 - loss: 0.1991 - val_accuracy: 0.8936 - val_loss: 0.2821\n",
      "Epoch 402/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9004 - loss: 0.2039 - val_accuracy: 0.8723 - val_loss: 0.2801\n",
      "Epoch 403/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8954 - loss: 0.2333 - val_accuracy: 0.8936 - val_loss: 0.2804\n",
      "Epoch 404/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9187 - loss: 0.1938 - val_accuracy: 0.8723 - val_loss: 0.2790\n",
      "Epoch 405/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9046 - loss: 0.2229 - val_accuracy: 0.8511 - val_loss: 0.2829\n",
      "Epoch 406/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9192 - loss: 0.2004 - val_accuracy: 0.8936 - val_loss: 0.2830\n",
      "Epoch 407/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9185 - loss: 0.2056 - val_accuracy: 0.8723 - val_loss: 0.2795\n",
      "Epoch 408/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9319 - loss: 0.1868 - val_accuracy: 0.8936 - val_loss: 0.2829\n",
      "Epoch 409/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9058 - loss: 0.2105 - val_accuracy: 0.8723 - val_loss: 0.2804\n",
      "Epoch 410/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8974 - loss: 0.2227 - val_accuracy: 0.8936 - val_loss: 0.2846\n",
      "Epoch 411/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8891 - loss: 0.2379 - val_accuracy: 0.8936 - val_loss: 0.2854\n",
      "Epoch 412/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9207 - loss: 0.2149 - val_accuracy: 0.8511 - val_loss: 0.2817\n",
      "Epoch 413/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8673 - loss: 0.2387 - val_accuracy: 0.8723 - val_loss: 0.2929\n",
      "Epoch 414/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9000 - loss: 0.2359 - val_accuracy: 0.8511 - val_loss: 0.2816\n",
      "Epoch 415/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8920 - loss: 0.2122 - val_accuracy: 0.8723 - val_loss: 0.2923\n",
      "Epoch 416/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9309 - loss: 0.2196 - val_accuracy: 0.8723 - val_loss: 0.2842\n",
      "Epoch 417/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8848 - loss: 0.2401 - val_accuracy: 0.8936 - val_loss: 0.2884\n",
      "Epoch 418/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9097 - loss: 0.2152 - val_accuracy: 0.8511 - val_loss: 0.2836\n",
      "Epoch 419/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8764 - loss: 0.2332 - val_accuracy: 0.8936 - val_loss: 0.2877\n",
      "Epoch 420/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8999 - loss: 0.2458 - val_accuracy: 0.8723 - val_loss: 0.2910\n",
      "Epoch 421/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9059 - loss: 0.2205 - val_accuracy: 0.8511 - val_loss: 0.2837\n",
      "Epoch 422/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9056 - loss: 0.2030 - val_accuracy: 0.8723 - val_loss: 0.2931\n",
      "Epoch 423/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9119 - loss: 0.2087 - val_accuracy: 0.8511 - val_loss: 0.2876\n",
      "Epoch 424/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8924 - loss: 0.2270 - val_accuracy: 0.8723 - val_loss: 0.2859\n",
      "Epoch 425/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9015 - loss: 0.2051 - val_accuracy: 0.8936 - val_loss: 0.2902\n",
      "Epoch 426/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8982 - loss: 0.2269 - val_accuracy: 0.8723 - val_loss: 0.2928\n",
      "Epoch 427/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9200 - loss: 0.2123 - val_accuracy: 0.8298 - val_loss: 0.2881\n",
      "Epoch 428/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9240 - loss: 0.2089 - val_accuracy: 0.8936 - val_loss: 0.2938\n",
      "Epoch 429/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8966 - loss: 0.2107 - val_accuracy: 0.8723 - val_loss: 0.3026\n",
      "Epoch 430/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8800 - loss: 0.2265 - val_accuracy: 0.8298 - val_loss: 0.2862\n",
      "Epoch 431/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9174 - loss: 0.2120 - val_accuracy: 0.8723 - val_loss: 0.2989\n",
      "Epoch 432/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9163 - loss: 0.2261 - val_accuracy: 0.8511 - val_loss: 0.2871\n",
      "Epoch 433/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9355 - loss: 0.1905 - val_accuracy: 0.8936 - val_loss: 0.2938\n",
      "Epoch 434/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9178 - loss: 0.2388 - val_accuracy: 0.8723 - val_loss: 0.2903\n",
      "Epoch 435/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.8891 - loss: 0.2280 - val_accuracy: 0.8723 - val_loss: 0.2951\n",
      "Epoch 436/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9106 - loss: 0.2413 - val_accuracy: 0.8936 - val_loss: 0.2953\n",
      "Epoch 437/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9234 - loss: 0.2295 - val_accuracy: 0.8511 - val_loss: 0.2915\n",
      "Epoch 438/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8954 - loss: 0.2361 - val_accuracy: 0.8511 - val_loss: 0.2915\n",
      "Epoch 439/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9287 - loss: 0.2127 - val_accuracy: 0.8723 - val_loss: 0.2972\n",
      "Epoch 440/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9026 - loss: 0.2195 - val_accuracy: 0.8723 - val_loss: 0.2883\n",
      "Epoch 441/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8692 - loss: 0.2412 - val_accuracy: 0.8511 - val_loss: 0.2931\n",
      "Epoch 442/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9083 - loss: 0.1975 - val_accuracy: 0.8723 - val_loss: 0.3050\n",
      "Epoch 443/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9276 - loss: 0.1923 - val_accuracy: 0.8723 - val_loss: 0.2946\n",
      "Epoch 444/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9049 - loss: 0.2163 - val_accuracy: 0.8723 - val_loss: 0.2972\n",
      "Epoch 445/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9109 - loss: 0.2037 - val_accuracy: 0.8723 - val_loss: 0.3003\n",
      "Epoch 446/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9289 - loss: 0.2014 - val_accuracy: 0.8936 - val_loss: 0.2958\n",
      "Epoch 447/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9201 - loss: 0.1949 - val_accuracy: 0.8298 - val_loss: 0.2959\n",
      "Epoch 448/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9283 - loss: 0.2041 - val_accuracy: 0.8723 - val_loss: 0.3162\n",
      "Epoch 449/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8958 - loss: 0.2249 - val_accuracy: 0.8511 - val_loss: 0.2923\n",
      "Epoch 450/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8896 - loss: 0.2142 - val_accuracy: 0.8511 - val_loss: 0.2958\n",
      "Epoch 451/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9193 - loss: 0.1778 - val_accuracy: 0.8723 - val_loss: 0.3025\n",
      "Epoch 452/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9044 - loss: 0.2118 - val_accuracy: 0.8511 - val_loss: 0.2964\n",
      "Epoch 453/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8980 - loss: 0.2319 - val_accuracy: 0.8723 - val_loss: 0.2939\n",
      "Epoch 454/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8943 - loss: 0.2163 - val_accuracy: 0.8936 - val_loss: 0.2960\n",
      "Epoch 455/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8918 - loss: 0.2143 - val_accuracy: 0.8723 - val_loss: 0.2939\n",
      "Epoch 456/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9179 - loss: 0.2050 - val_accuracy: 0.8936 - val_loss: 0.3003\n",
      "Epoch 457/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9107 - loss: 0.2191 - val_accuracy: 0.8936 - val_loss: 0.2999\n",
      "Epoch 458/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8846 - loss: 0.2321 - val_accuracy: 0.8511 - val_loss: 0.2974\n",
      "Epoch 459/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9095 - loss: 0.2005 - val_accuracy: 0.8723 - val_loss: 0.3080\n",
      "Epoch 460/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9145 - loss: 0.1939 - val_accuracy: 0.8723 - val_loss: 0.2955\n",
      "Epoch 461/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9019 - loss: 0.1865 - val_accuracy: 0.8936 - val_loss: 0.3019\n",
      "Epoch 462/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8959 - loss: 0.2271 - val_accuracy: 0.8936 - val_loss: 0.3027\n",
      "Epoch 463/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8954 - loss: 0.2187 - val_accuracy: 0.8085 - val_loss: 0.2975\n",
      "Epoch 464/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9255 - loss: 0.1854 - val_accuracy: 0.8723 - val_loss: 0.3126\n",
      "Epoch 465/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9240 - loss: 0.1977 - val_accuracy: 0.8511 - val_loss: 0.2951\n",
      "Epoch 466/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9072 - loss: 0.2123 - val_accuracy: 0.8511 - val_loss: 0.2955\n",
      "Epoch 467/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9014 - loss: 0.2054 - val_accuracy: 0.8723 - val_loss: 0.3086\n",
      "Epoch 468/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9279 - loss: 0.1884 - val_accuracy: 0.8511 - val_loss: 0.2983\n",
      "Epoch 469/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8872 - loss: 0.2171 - val_accuracy: 0.8936 - val_loss: 0.3038\n",
      "Epoch 470/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9211 - loss: 0.1993 - val_accuracy: 0.8723 - val_loss: 0.2976\n",
      "Epoch 471/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9248 - loss: 0.1866 - val_accuracy: 0.8511 - val_loss: 0.2984\n",
      "Epoch 472/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9200 - loss: 0.1987 - val_accuracy: 0.8936 - val_loss: 0.3041\n",
      "Epoch 473/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9116 - loss: 0.2105 - val_accuracy: 0.8936 - val_loss: 0.3077\n",
      "Epoch 474/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9187 - loss: 0.1970 - val_accuracy: 0.8511 - val_loss: 0.2967\n",
      "Epoch 475/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8787 - loss: 0.2337 - val_accuracy: 0.8511 - val_loss: 0.2979\n",
      "Epoch 476/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8916 - loss: 0.2515 - val_accuracy: 0.8936 - val_loss: 0.3076\n",
      "Epoch 477/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9040 - loss: 0.2273 - val_accuracy: 0.8723 - val_loss: 0.3018\n",
      "Epoch 478/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8772 - loss: 0.2338 - val_accuracy: 0.8723 - val_loss: 0.3032\n",
      "Epoch 479/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8900 - loss: 0.2374 - val_accuracy: 0.8936 - val_loss: 0.3067\n",
      "Epoch 480/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9172 - loss: 0.1867 - val_accuracy: 0.8723 - val_loss: 0.3006\n",
      "Epoch 481/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9042 - loss: 0.2181 - val_accuracy: 0.8723 - val_loss: 0.3031\n",
      "Epoch 482/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9217 - loss: 0.1936 - val_accuracy: 0.8723 - val_loss: 0.3040\n",
      "Epoch 483/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9149 - loss: 0.1797 - val_accuracy: 0.8511 - val_loss: 0.2998\n",
      "Epoch 484/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9016 - loss: 0.2005 - val_accuracy: 0.8936 - val_loss: 0.3142\n",
      "Epoch 485/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9222 - loss: 0.2016 - val_accuracy: 0.8723 - val_loss: 0.3018\n",
      "Epoch 486/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9017 - loss: 0.2148 - val_accuracy: 0.8511 - val_loss: 0.3027\n",
      "Epoch 487/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9162 - loss: 0.1765 - val_accuracy: 0.8936 - val_loss: 0.3135\n",
      "Epoch 488/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9181 - loss: 0.1914 - val_accuracy: 0.8511 - val_loss: 0.3035\n",
      "Epoch 489/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8862 - loss: 0.2124 - val_accuracy: 0.8511 - val_loss: 0.3008\n",
      "Epoch 490/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9105 - loss: 0.1943 - val_accuracy: 0.8936 - val_loss: 0.3158\n",
      "Epoch 491/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9340 - loss: 0.1901 - val_accuracy: 0.8511 - val_loss: 0.3053\n",
      "Epoch 492/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8995 - loss: 0.1995 - val_accuracy: 0.8511 - val_loss: 0.3061\n",
      "Epoch 493/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9051 - loss: 0.2055 - val_accuracy: 0.8723 - val_loss: 0.3158\n",
      "Epoch 494/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9229 - loss: 0.1834 - val_accuracy: 0.8511 - val_loss: 0.3045\n",
      "Epoch 495/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9007 - loss: 0.2100 - val_accuracy: 0.8723 - val_loss: 0.3070\n",
      "Epoch 496/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9115 - loss: 0.1881 - val_accuracy: 0.8936 - val_loss: 0.3121\n",
      "Epoch 497/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9133 - loss: 0.2009 - val_accuracy: 0.8511 - val_loss: 0.3112\n",
      "Epoch 498/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8982 - loss: 0.2144 - val_accuracy: 0.8936 - val_loss: 0.3131\n",
      "Epoch 499/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8804 - loss: 0.2252 - val_accuracy: 0.8723 - val_loss: 0.3088\n",
      "Epoch 500/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9256 - loss: 0.1763 - val_accuracy: 0.8936 - val_loss: 0.3083\n",
      "Epoch 501/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9058 - loss: 0.1944 - val_accuracy: 0.8511 - val_loss: 0.3090\n",
      "Epoch 502/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9045 - loss: 0.2079 - val_accuracy: 0.8936 - val_loss: 0.3183\n",
      "Epoch 503/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9116 - loss: 0.1942 - val_accuracy: 0.8723 - val_loss: 0.3117\n",
      "Epoch 504/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9439 - loss: 0.1712 - val_accuracy: 0.8723 - val_loss: 0.3123\n",
      "Epoch 505/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9195 - loss: 0.1922 - val_accuracy: 0.8511 - val_loss: 0.3094\n",
      "Epoch 506/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9022 - loss: 0.2130 - val_accuracy: 0.8936 - val_loss: 0.3221\n",
      "Epoch 507/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9072 - loss: 0.1915 - val_accuracy: 0.8511 - val_loss: 0.3094\n",
      "Epoch 508/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8943 - loss: 0.2064 - val_accuracy: 0.8936 - val_loss: 0.3148\n",
      "Epoch 509/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8975 - loss: 0.2264 - val_accuracy: 0.8723 - val_loss: 0.3155\n",
      "Epoch 510/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9287 - loss: 0.1781 - val_accuracy: 0.8511 - val_loss: 0.3146\n",
      "Epoch 511/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9177 - loss: 0.1963 - val_accuracy: 0.8936 - val_loss: 0.3147\n",
      "Epoch 512/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9136 - loss: 0.1930 - val_accuracy: 0.8511 - val_loss: 0.3127\n",
      "Epoch 513/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9050 - loss: 0.1824 - val_accuracy: 0.8936 - val_loss: 0.3172\n",
      "Epoch 514/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9115 - loss: 0.1886 - val_accuracy: 0.8511 - val_loss: 0.3166\n",
      "Epoch 515/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9016 - loss: 0.2230 - val_accuracy: 0.8936 - val_loss: 0.3158\n",
      "Epoch 516/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8970 - loss: 0.2033 - val_accuracy: 0.8511 - val_loss: 0.3167\n",
      "Epoch 517/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9132 - loss: 0.2047 - val_accuracy: 0.8936 - val_loss: 0.3273\n",
      "Epoch 518/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9264 - loss: 0.1766 - val_accuracy: 0.8511 - val_loss: 0.3151\n",
      "Epoch 519/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9282 - loss: 0.1881 - val_accuracy: 0.8511 - val_loss: 0.3161\n",
      "Epoch 520/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8816 - loss: 0.2296 - val_accuracy: 0.8936 - val_loss: 0.3191\n",
      "Epoch 521/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8984 - loss: 0.2349 - val_accuracy: 0.8511 - val_loss: 0.3159\n",
      "Epoch 522/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9289 - loss: 0.2021 - val_accuracy: 0.8723 - val_loss: 0.3208\n",
      "Epoch 523/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9070 - loss: 0.2133 - val_accuracy: 0.8511 - val_loss: 0.3175\n",
      "Epoch 524/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9043 - loss: 0.2335 - val_accuracy: 0.8936 - val_loss: 0.3169\n",
      "Epoch 525/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9146 - loss: 0.2146 - val_accuracy: 0.8936 - val_loss: 0.3220\n",
      "Epoch 526/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9230 - loss: 0.1555 - val_accuracy: 0.8511 - val_loss: 0.3207\n",
      "Epoch 527/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9102 - loss: 0.2002 - val_accuracy: 0.8936 - val_loss: 0.3199\n",
      "Epoch 528/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8917 - loss: 0.1989 - val_accuracy: 0.8723 - val_loss: 0.3229\n",
      "Epoch 529/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9163 - loss: 0.2033 - val_accuracy: 0.8936 - val_loss: 0.3228\n",
      "Epoch 530/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8882 - loss: 0.2293 - val_accuracy: 0.8723 - val_loss: 0.3212\n",
      "Epoch 531/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8983 - loss: 0.1950 - val_accuracy: 0.8511 - val_loss: 0.3221\n",
      "Epoch 532/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9183 - loss: 0.1817 - val_accuracy: 0.8936 - val_loss: 0.3265\n",
      "Epoch 533/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9231 - loss: 0.1856 - val_accuracy: 0.8511 - val_loss: 0.3178\n",
      "Epoch 534/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9386 - loss: 0.1856 - val_accuracy: 0.8936 - val_loss: 0.3263\n",
      "Epoch 535/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9187 - loss: 0.1790 - val_accuracy: 0.8511 - val_loss: 0.3221\n",
      "Epoch 536/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9073 - loss: 0.1913 - val_accuracy: 0.8511 - val_loss: 0.3253\n",
      "Epoch 537/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9116 - loss: 0.1746 - val_accuracy: 0.8936 - val_loss: 0.3297\n",
      "Epoch 538/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9163 - loss: 0.1879 - val_accuracy: 0.8936 - val_loss: 0.3270\n",
      "Epoch 539/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9100 - loss: 0.1868 - val_accuracy: 0.8511 - val_loss: 0.3250\n",
      "Epoch 540/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9312 - loss: 0.1872 - val_accuracy: 0.8511 - val_loss: 0.3222\n",
      "Epoch 541/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9029 - loss: 0.2012 - val_accuracy: 0.8936 - val_loss: 0.3276\n",
      "Epoch 542/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9107 - loss: 0.1716 - val_accuracy: 0.8511 - val_loss: 0.3261\n",
      "Epoch 543/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9086 - loss: 0.2053 - val_accuracy: 0.8936 - val_loss: 0.3295\n",
      "Epoch 544/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9265 - loss: 0.1798 - val_accuracy: 0.8511 - val_loss: 0.3244\n",
      "Epoch 545/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8894 - loss: 0.2133 - val_accuracy: 0.8936 - val_loss: 0.3361\n",
      "Epoch 546/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9132 - loss: 0.1954 - val_accuracy: 0.8511 - val_loss: 0.3288\n",
      "Epoch 547/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9072 - loss: 0.1960 - val_accuracy: 0.8511 - val_loss: 0.3321\n",
      "Epoch 548/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9009 - loss: 0.1986 - val_accuracy: 0.8936 - val_loss: 0.3327\n",
      "Epoch 549/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9261 - loss: 0.1835 - val_accuracy: 0.8511 - val_loss: 0.3208\n",
      "Epoch 550/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8954 - loss: 0.2012 - val_accuracy: 0.8936 - val_loss: 0.3332\n",
      "Epoch 551/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8825 - loss: 0.2262 - val_accuracy: 0.8936 - val_loss: 0.3296\n",
      "Epoch 552/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9028 - loss: 0.1864 - val_accuracy: 0.8511 - val_loss: 0.3300\n",
      "Epoch 553/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9138 - loss: 0.1683 - val_accuracy: 0.8511 - val_loss: 0.3319\n",
      "Epoch 554/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9198 - loss: 0.1934 - val_accuracy: 0.8936 - val_loss: 0.3329\n",
      "Epoch 555/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9174 - loss: 0.2125 - val_accuracy: 0.8511 - val_loss: 0.3252\n",
      "Epoch 556/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8940 - loss: 0.1991 - val_accuracy: 0.8511 - val_loss: 0.3252\n",
      "Epoch 557/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9180 - loss: 0.1890 - val_accuracy: 0.8723 - val_loss: 0.3458\n",
      "Epoch 558/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9290 - loss: 0.1686 - val_accuracy: 0.8085 - val_loss: 0.3251\n",
      "Epoch 559/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9044 - loss: 0.1858 - val_accuracy: 0.8936 - val_loss: 0.3358\n",
      "Epoch 560/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9180 - loss: 0.2055 - val_accuracy: 0.8511 - val_loss: 0.3313\n",
      "Epoch 561/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9318 - loss: 0.1838 - val_accuracy: 0.8298 - val_loss: 0.3307\n",
      "Epoch 562/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9227 - loss: 0.1811 - val_accuracy: 0.8936 - val_loss: 0.3433\n",
      "Epoch 563/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8991 - loss: 0.1997 - val_accuracy: 0.8511 - val_loss: 0.3276\n",
      "Epoch 564/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8894 - loss: 0.2235 - val_accuracy: 0.8936 - val_loss: 0.3317\n",
      "Epoch 565/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9132 - loss: 0.1837 - val_accuracy: 0.8936 - val_loss: 0.3338\n",
      "Epoch 566/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9220 - loss: 0.1866 - val_accuracy: 0.8511 - val_loss: 0.3328\n",
      "Epoch 567/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9033 - loss: 0.2057 - val_accuracy: 0.8511 - val_loss: 0.3355\n",
      "Epoch 568/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9459 - loss: 0.1628 - val_accuracy: 0.8511 - val_loss: 0.3336\n",
      "Epoch 569/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9145 - loss: 0.1806 - val_accuracy: 0.8723 - val_loss: 0.3335\n",
      "Epoch 570/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9135 - loss: 0.1663 - val_accuracy: 0.8723 - val_loss: 0.3333\n",
      "Epoch 571/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9339 - loss: 0.1961 - val_accuracy: 0.8936 - val_loss: 0.3390\n",
      "Epoch 572/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9070 - loss: 0.2002 - val_accuracy: 0.8511 - val_loss: 0.3330\n",
      "Epoch 573/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9191 - loss: 0.1763 - val_accuracy: 0.8936 - val_loss: 0.3377\n",
      "Epoch 574/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8886 - loss: 0.2025 - val_accuracy: 0.8511 - val_loss: 0.3354\n",
      "Epoch 575/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8951 - loss: 0.1957 - val_accuracy: 0.8936 - val_loss: 0.3455\n",
      "Epoch 576/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9271 - loss: 0.1667 - val_accuracy: 0.8936 - val_loss: 0.3369\n",
      "Epoch 577/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9135 - loss: 0.1773 - val_accuracy: 0.8511 - val_loss: 0.3380\n",
      "Epoch 578/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8990 - loss: 0.1926 - val_accuracy: 0.8511 - val_loss: 0.3387\n",
      "Epoch 579/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9318 - loss: 0.1848 - val_accuracy: 0.8723 - val_loss: 0.3547\n",
      "Epoch 580/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9181 - loss: 0.1871 - val_accuracy: 0.8511 - val_loss: 0.3287\n",
      "Epoch 581/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9286 - loss: 0.1824 - val_accuracy: 0.8936 - val_loss: 0.3405\n",
      "Epoch 582/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9303 - loss: 0.1737 - val_accuracy: 0.8723 - val_loss: 0.3512\n",
      "Epoch 583/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9234 - loss: 0.1780 - val_accuracy: 0.8298 - val_loss: 0.3404\n",
      "Epoch 584/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8944 - loss: 0.2062 - val_accuracy: 0.8936 - val_loss: 0.3437\n",
      "Epoch 585/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9265 - loss: 0.1621 - val_accuracy: 0.8936 - val_loss: 0.3421\n",
      "Epoch 586/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9075 - loss: 0.1962 - val_accuracy: 0.8511 - val_loss: 0.3370\n",
      "Epoch 587/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9024 - loss: 0.1937 - val_accuracy: 0.8936 - val_loss: 0.3382\n",
      "Epoch 588/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8957 - loss: 0.2031 - val_accuracy: 0.8511 - val_loss: 0.3367\n",
      "Epoch 589/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8976 - loss: 0.1780 - val_accuracy: 0.8723 - val_loss: 0.3486\n",
      "Epoch 590/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9206 - loss: 0.1723 - val_accuracy: 0.8936 - val_loss: 0.3404\n",
      "Epoch 591/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9079 - loss: 0.1912 - val_accuracy: 0.8511 - val_loss: 0.3378\n",
      "Epoch 592/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8963 - loss: 0.2143 - val_accuracy: 0.8936 - val_loss: 0.3533\n",
      "Epoch 593/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8992 - loss: 0.1964 - val_accuracy: 0.8511 - val_loss: 0.3441\n",
      "Epoch 594/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9066 - loss: 0.1777 - val_accuracy: 0.8511 - val_loss: 0.3415\n",
      "Epoch 595/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9326 - loss: 0.1727 - val_accuracy: 0.8723 - val_loss: 0.3542\n",
      "Epoch 596/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9246 - loss: 0.1725 - val_accuracy: 0.8511 - val_loss: 0.3367\n",
      "Epoch 597/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9314 - loss: 0.1548 - val_accuracy: 0.8511 - val_loss: 0.3430\n",
      "Epoch 598/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9463 - loss: 0.1495 - val_accuracy: 0.8723 - val_loss: 0.3599\n",
      "Epoch 599/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9096 - loss: 0.1987 - val_accuracy: 0.8511 - val_loss: 0.3459\n",
      "Epoch 600/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9078 - loss: 0.1832 - val_accuracy: 0.8936 - val_loss: 0.3504\n",
      "Epoch 601/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9282 - loss: 0.1939 - val_accuracy: 0.8511 - val_loss: 0.3470\n",
      "Epoch 602/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9265 - loss: 0.1637 - val_accuracy: 0.8511 - val_loss: 0.3466\n",
      "Epoch 603/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9279 - loss: 0.1727 - val_accuracy: 0.8723 - val_loss: 0.3466\n",
      "Epoch 604/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9374 - loss: 0.1538 - val_accuracy: 0.8511 - val_loss: 0.3455\n",
      "Epoch 605/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9148 - loss: 0.1893 - val_accuracy: 0.8511 - val_loss: 0.3439\n",
      "Epoch 606/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8793 - loss: 0.2082 - val_accuracy: 0.8936 - val_loss: 0.3534\n",
      "Epoch 607/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9341 - loss: 0.1559 - val_accuracy: 0.8936 - val_loss: 0.3537\n",
      "Epoch 608/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9255 - loss: 0.1535 - val_accuracy: 0.8085 - val_loss: 0.3538\n",
      "Epoch 609/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9409 - loss: 0.1674 - val_accuracy: 0.8936 - val_loss: 0.3579\n",
      "Epoch 610/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9248 - loss: 0.1648 - val_accuracy: 0.8936 - val_loss: 0.3529\n",
      "Epoch 611/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9131 - loss: 0.1726 - val_accuracy: 0.8298 - val_loss: 0.3478\n",
      "Epoch 612/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9229 - loss: 0.1624 - val_accuracy: 0.8723 - val_loss: 0.3679\n",
      "Epoch 613/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9251 - loss: 0.1676 - val_accuracy: 0.8511 - val_loss: 0.3438\n",
      "Epoch 614/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9134 - loss: 0.1818 - val_accuracy: 0.8723 - val_loss: 0.3592\n",
      "Epoch 615/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9181 - loss: 0.1777 - val_accuracy: 0.8723 - val_loss: 0.3618\n",
      "Epoch 616/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9251 - loss: 0.1831 - val_accuracy: 0.8511 - val_loss: 0.3528\n",
      "Epoch 617/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9085 - loss: 0.1888 - val_accuracy: 0.8511 - val_loss: 0.3502\n",
      "Epoch 618/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9001 - loss: 0.1776 - val_accuracy: 0.8723 - val_loss: 0.3691\n",
      "Epoch 619/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9086 - loss: 0.1799 - val_accuracy: 0.8298 - val_loss: 0.3546\n",
      "Epoch 620/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9247 - loss: 0.1657 - val_accuracy: 0.8511 - val_loss: 0.3590\n",
      "Epoch 621/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9050 - loss: 0.2082 - val_accuracy: 0.8511 - val_loss: 0.3563\n",
      "Epoch 622/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9205 - loss: 0.1589 - val_accuracy: 0.8511 - val_loss: 0.3556\n",
      "Epoch 623/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9276 - loss: 0.1733 - val_accuracy: 0.8723 - val_loss: 0.3661\n",
      "Epoch 624/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9442 - loss: 0.1559 - val_accuracy: 0.8298 - val_loss: 0.3522\n",
      "Epoch 625/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9398 - loss: 0.1684 - val_accuracy: 0.8936 - val_loss: 0.3604\n",
      "Epoch 626/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9108 - loss: 0.1811 - val_accuracy: 0.8936 - val_loss: 0.3631\n",
      "Epoch 627/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9434 - loss: 0.1511 - val_accuracy: 0.8085 - val_loss: 0.3603\n",
      "Epoch 628/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9277 - loss: 0.1786 - val_accuracy: 0.8723 - val_loss: 0.3758\n",
      "Epoch 629/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9161 - loss: 0.1783 - val_accuracy: 0.8511 - val_loss: 0.3542\n",
      "Epoch 630/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8569 - loss: 0.2204 - val_accuracy: 0.8511 - val_loss: 0.3522\n",
      "Epoch 631/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9234 - loss: 0.1606 - val_accuracy: 0.8723 - val_loss: 0.3712\n",
      "Epoch 632/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9128 - loss: 0.1857 - val_accuracy: 0.8298 - val_loss: 0.3590\n",
      "Epoch 633/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9187 - loss: 0.1861 - val_accuracy: 0.8936 - val_loss: 0.3677\n",
      "Epoch 634/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8991 - loss: 0.1896 - val_accuracy: 0.8511 - val_loss: 0.3590\n",
      "Epoch 635/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9181 - loss: 0.1691 - val_accuracy: 0.8511 - val_loss: 0.3591\n",
      "Epoch 636/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9258 - loss: 0.1550 - val_accuracy: 0.8936 - val_loss: 0.3630\n",
      "Epoch 637/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8773 - loss: 0.2169 - val_accuracy: 0.8298 - val_loss: 0.3599\n",
      "Epoch 638/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9318 - loss: 0.1548 - val_accuracy: 0.8723 - val_loss: 0.3737\n",
      "Epoch 639/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9206 - loss: 0.1753 - val_accuracy: 0.8511 - val_loss: 0.3596\n",
      "Epoch 640/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9064 - loss: 0.1730 - val_accuracy: 0.8511 - val_loss: 0.3643\n",
      "Epoch 641/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9212 - loss: 0.1829 - val_accuracy: 0.8936 - val_loss: 0.3692\n",
      "Epoch 642/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9313 - loss: 0.1803 - val_accuracy: 0.8511 - val_loss: 0.3559\n",
      "Epoch 643/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9229 - loss: 0.1651 - val_accuracy: 0.8723 - val_loss: 0.3642\n",
      "Epoch 644/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9261 - loss: 0.1538 - val_accuracy: 0.8936 - val_loss: 0.3720\n",
      "Epoch 645/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9135 - loss: 0.1701 - val_accuracy: 0.8298 - val_loss: 0.3649\n",
      "Epoch 646/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9373 - loss: 0.1571 - val_accuracy: 0.8936 - val_loss: 0.3731\n",
      "Epoch 647/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8980 - loss: 0.1830 - val_accuracy: 0.8936 - val_loss: 0.3681\n",
      "Epoch 648/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9269 - loss: 0.1698 - val_accuracy: 0.8511 - val_loss: 0.3634\n",
      "Epoch 649/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9505 - loss: 0.1597 - val_accuracy: 0.8511 - val_loss: 0.3676\n",
      "Epoch 650/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9074 - loss: 0.1963 - val_accuracy: 0.8936 - val_loss: 0.3762\n",
      "Epoch 651/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9407 - loss: 0.1629 - val_accuracy: 0.8511 - val_loss: 0.3712\n",
      "Epoch 652/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9211 - loss: 0.1709 - val_accuracy: 0.8511 - val_loss: 0.3618\n",
      "Epoch 653/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9172 - loss: 0.1801 - val_accuracy: 0.8936 - val_loss: 0.3680\n",
      "Epoch 654/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9490 - loss: 0.1399 - val_accuracy: 0.8511 - val_loss: 0.3625\n",
      "Epoch 655/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9071 - loss: 0.1734 - val_accuracy: 0.8511 - val_loss: 0.3661\n",
      "Epoch 656/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9181 - loss: 0.1817 - val_accuracy: 0.8936 - val_loss: 0.3713\n",
      "Epoch 657/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8962 - loss: 0.1844 - val_accuracy: 0.8511 - val_loss: 0.3720\n",
      "Epoch 658/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9273 - loss: 0.1774 - val_accuracy: 0.8936 - val_loss: 0.3797\n",
      "Epoch 659/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9265 - loss: 0.1600 - val_accuracy: 0.8511 - val_loss: 0.3682\n",
      "Epoch 660/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9167 - loss: 0.1636 - val_accuracy: 0.8511 - val_loss: 0.3729\n",
      "Epoch 661/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9293 - loss: 0.1698 - val_accuracy: 0.8723 - val_loss: 0.3881\n",
      "Epoch 662/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9050 - loss: 0.2081 - val_accuracy: 0.8298 - val_loss: 0.3651\n",
      "Epoch 663/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9006 - loss: 0.1780 - val_accuracy: 0.8723 - val_loss: 0.3800\n",
      "Epoch 664/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9131 - loss: 0.1773 - val_accuracy: 0.8298 - val_loss: 0.3664\n",
      "Epoch 665/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9559 - loss: 0.1375 - val_accuracy: 0.8511 - val_loss: 0.3730\n",
      "Epoch 666/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9135 - loss: 0.1962 - val_accuracy: 0.8936 - val_loss: 0.3754\n",
      "Epoch 667/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9133 - loss: 0.1827 - val_accuracy: 0.8298 - val_loss: 0.3672\n",
      "Epoch 668/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9087 - loss: 0.1729 - val_accuracy: 0.8723 - val_loss: 0.3833\n",
      "Epoch 669/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8986 - loss: 0.1923 - val_accuracy: 0.8298 - val_loss: 0.3786\n",
      "Epoch 670/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9414 - loss: 0.1615 - val_accuracy: 0.8723 - val_loss: 0.3779\n",
      "Epoch 671/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9021 - loss: 0.1871 - val_accuracy: 0.8298 - val_loss: 0.3661\n",
      "Epoch 672/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9191 - loss: 0.1576 - val_accuracy: 0.8723 - val_loss: 0.3780\n",
      "Epoch 673/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9254 - loss: 0.1798 - val_accuracy: 0.8511 - val_loss: 0.3741\n",
      "Epoch 674/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9238 - loss: 0.1578 - val_accuracy: 0.8298 - val_loss: 0.3746\n",
      "Epoch 675/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9267 - loss: 0.1565 - val_accuracy: 0.8723 - val_loss: 0.3852\n",
      "Epoch 676/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9360 - loss: 0.1641 - val_accuracy: 0.8936 - val_loss: 0.3821\n",
      "Epoch 677/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9366 - loss: 0.1519 - val_accuracy: 0.8298 - val_loss: 0.3675\n",
      "Epoch 678/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9364 - loss: 0.1522 - val_accuracy: 0.8936 - val_loss: 0.3791\n",
      "Epoch 679/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9003 - loss: 0.1727 - val_accuracy: 0.8936 - val_loss: 0.3803\n",
      "Epoch 680/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9578 - loss: 0.1507 - val_accuracy: 0.8298 - val_loss: 0.3744\n",
      "Epoch 681/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8992 - loss: 0.1880 - val_accuracy: 0.8511 - val_loss: 0.3772\n",
      "Epoch 682/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9282 - loss: 0.1626 - val_accuracy: 0.8936 - val_loss: 0.3861\n",
      "Epoch 683/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8998 - loss: 0.1784 - val_accuracy: 0.8511 - val_loss: 0.3794\n",
      "Epoch 684/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9189 - loss: 0.1670 - val_accuracy: 0.8936 - val_loss: 0.3886\n",
      "Epoch 685/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9346 - loss: 0.1558 - val_accuracy: 0.8298 - val_loss: 0.3792\n",
      "Epoch 686/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9413 - loss: 0.1473 - val_accuracy: 0.8723 - val_loss: 0.3810\n",
      "Epoch 687/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8902 - loss: 0.2045 - val_accuracy: 0.8511 - val_loss: 0.3825\n",
      "Epoch 688/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9168 - loss: 0.1715 - val_accuracy: 0.8936 - val_loss: 0.3860\n",
      "Epoch 689/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8853 - loss: 0.2100 - val_accuracy: 0.8511 - val_loss: 0.3834\n",
      "Epoch 690/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9198 - loss: 0.1730 - val_accuracy: 0.8511 - val_loss: 0.3868\n",
      "Epoch 691/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9342 - loss: 0.1463 - val_accuracy: 0.8511 - val_loss: 0.3783\n",
      "Epoch 692/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9050 - loss: 0.1722 - val_accuracy: 0.8723 - val_loss: 0.3900\n",
      "Epoch 693/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9117 - loss: 0.1633 - val_accuracy: 0.8298 - val_loss: 0.3852\n",
      "Epoch 694/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9175 - loss: 0.1867 - val_accuracy: 0.8936 - val_loss: 0.3906\n",
      "Epoch 695/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8989 - loss: 0.1811 - val_accuracy: 0.8298 - val_loss: 0.3837\n",
      "Epoch 696/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9273 - loss: 0.1461 - val_accuracy: 0.8511 - val_loss: 0.3875\n",
      "Epoch 697/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9013 - loss: 0.1839 - val_accuracy: 0.8723 - val_loss: 0.4037\n",
      "Epoch 698/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9099 - loss: 0.1892 - val_accuracy: 0.8298 - val_loss: 0.3886\n",
      "Epoch 699/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9275 - loss: 0.1829 - val_accuracy: 0.8723 - val_loss: 0.3972\n",
      "Epoch 700/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9230 - loss: 0.1690 - val_accuracy: 0.8511 - val_loss: 0.3897\n",
      "Epoch 701/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9165 - loss: 0.1784 - val_accuracy: 0.8511 - val_loss: 0.3830\n",
      "Epoch 702/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9450 - loss: 0.1407 - val_accuracy: 0.8511 - val_loss: 0.3875\n",
      "Epoch 703/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9380 - loss: 0.1730 - val_accuracy: 0.8936 - val_loss: 0.3867\n",
      "Epoch 704/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9122 - loss: 0.1722 - val_accuracy: 0.8298 - val_loss: 0.3835\n",
      "Epoch 705/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9202 - loss: 0.1673 - val_accuracy: 0.8723 - val_loss: 0.3934\n",
      "Epoch 706/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9258 - loss: 0.1704 - val_accuracy: 0.8298 - val_loss: 0.3898\n",
      "Epoch 707/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9373 - loss: 0.1517 - val_accuracy: 0.8511 - val_loss: 0.3908\n",
      "Epoch 708/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9277 - loss: 0.1477 - val_accuracy: 0.8723 - val_loss: 0.3933\n",
      "Epoch 709/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9375 - loss: 0.1453 - val_accuracy: 0.8723 - val_loss: 0.3841\n",
      "Epoch 710/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9387 - loss: 0.1585 - val_accuracy: 0.8298 - val_loss: 0.3871\n",
      "Epoch 711/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9158 - loss: 0.1739 - val_accuracy: 0.8723 - val_loss: 0.4030\n",
      "Epoch 712/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9065 - loss: 0.1799 - val_accuracy: 0.8511 - val_loss: 0.3910\n",
      "Epoch 713/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9112 - loss: 0.1910 - val_accuracy: 0.8511 - val_loss: 0.3873\n",
      "Epoch 714/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9142 - loss: 0.1636 - val_accuracy: 0.8936 - val_loss: 0.3942\n",
      "Epoch 715/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9165 - loss: 0.1581 - val_accuracy: 0.8298 - val_loss: 0.3931\n",
      "Epoch 716/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9197 - loss: 0.1509 - val_accuracy: 0.8723 - val_loss: 0.4024\n",
      "Epoch 717/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9157 - loss: 0.1468 - val_accuracy: 0.8298 - val_loss: 0.3942\n",
      "Epoch 718/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9290 - loss: 0.1479 - val_accuracy: 0.8723 - val_loss: 0.4004\n",
      "Epoch 719/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9207 - loss: 0.1805 - val_accuracy: 0.8298 - val_loss: 0.3905\n",
      "Epoch 720/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9166 - loss: 0.1903 - val_accuracy: 0.8723 - val_loss: 0.4017\n",
      "Epoch 721/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9279 - loss: 0.1524 - val_accuracy: 0.8298 - val_loss: 0.3961\n",
      "Epoch 722/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9059 - loss: 0.1814 - val_accuracy: 0.8511 - val_loss: 0.3985\n",
      "Epoch 723/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9370 - loss: 0.1618 - val_accuracy: 0.8723 - val_loss: 0.4041\n",
      "Epoch 724/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9232 - loss: 0.1678 - val_accuracy: 0.8298 - val_loss: 0.3988\n",
      "Epoch 725/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9193 - loss: 0.1579 - val_accuracy: 0.8298 - val_loss: 0.4024\n",
      "Epoch 726/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9030 - loss: 0.1730 - val_accuracy: 0.8723 - val_loss: 0.4154\n",
      "Epoch 727/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8926 - loss: 0.1734 - val_accuracy: 0.8085 - val_loss: 0.3994\n",
      "Epoch 728/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9188 - loss: 0.1648 - val_accuracy: 0.8723 - val_loss: 0.4161\n",
      "Epoch 729/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9306 - loss: 0.1543 - val_accuracy: 0.8936 - val_loss: 0.4090\n",
      "Epoch 730/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9200 - loss: 0.1709 - val_accuracy: 0.8085 - val_loss: 0.3975\n",
      "Epoch 731/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8987 - loss: 0.1774 - val_accuracy: 0.8723 - val_loss: 0.4063\n",
      "Epoch 732/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9187 - loss: 0.1870 - val_accuracy: 0.8511 - val_loss: 0.3998\n",
      "Epoch 733/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9299 - loss: 0.1584 - val_accuracy: 0.8298 - val_loss: 0.4013\n",
      "Epoch 734/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9401 - loss: 0.1636 - val_accuracy: 0.8298 - val_loss: 0.4079\n",
      "Epoch 735/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9151 - loss: 0.1708 - val_accuracy: 0.8723 - val_loss: 0.4125\n",
      "Epoch 736/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9394 - loss: 0.1484 - val_accuracy: 0.8511 - val_loss: 0.4066\n",
      "Epoch 737/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9429 - loss: 0.1474 - val_accuracy: 0.8085 - val_loss: 0.4096\n",
      "Epoch 738/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9082 - loss: 0.1711 - val_accuracy: 0.8723 - val_loss: 0.4290\n",
      "Epoch 739/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9220 - loss: 0.1540 - val_accuracy: 0.8298 - val_loss: 0.3998\n",
      "Epoch 740/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9199 - loss: 0.1642 - val_accuracy: 0.8298 - val_loss: 0.4037\n",
      "Epoch 741/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9390 - loss: 0.1361 - val_accuracy: 0.8723 - val_loss: 0.4142\n",
      "Epoch 742/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9401 - loss: 0.1439 - val_accuracy: 0.8298 - val_loss: 0.4049\n",
      "Epoch 743/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9330 - loss: 0.1688 - val_accuracy: 0.8298 - val_loss: 0.4050\n",
      "Epoch 744/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9211 - loss: 0.1637 - val_accuracy: 0.8936 - val_loss: 0.4096\n",
      "Epoch 745/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9284 - loss: 0.1460 - val_accuracy: 0.8298 - val_loss: 0.4051\n",
      "Epoch 746/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9269 - loss: 0.1604 - val_accuracy: 0.8511 - val_loss: 0.4117\n",
      "Epoch 747/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9304 - loss: 0.1461 - val_accuracy: 0.8511 - val_loss: 0.4087\n",
      "Epoch 748/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8988 - loss: 0.1733 - val_accuracy: 0.8723 - val_loss: 0.4102\n",
      "Epoch 749/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9338 - loss: 0.1390 - val_accuracy: 0.8298 - val_loss: 0.4032\n",
      "Epoch 750/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9247 - loss: 0.1529 - val_accuracy: 0.8511 - val_loss: 0.4070\n",
      "Epoch 751/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9288 - loss: 0.1590 - val_accuracy: 0.8511 - val_loss: 0.4099\n",
      "Epoch 752/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9059 - loss: 0.1649 - val_accuracy: 0.8298 - val_loss: 0.4110\n",
      "Epoch 753/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9041 - loss: 0.1650 - val_accuracy: 0.8511 - val_loss: 0.4180\n",
      "Epoch 754/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9123 - loss: 0.1557 - val_accuracy: 0.8298 - val_loss: 0.4146\n",
      "Epoch 755/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9173 - loss: 0.1768 - val_accuracy: 0.8936 - val_loss: 0.4193\n",
      "Epoch 756/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9221 - loss: 0.1589 - val_accuracy: 0.8085 - val_loss: 0.4130\n",
      "Epoch 757/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9292 - loss: 0.1569 - val_accuracy: 0.8936 - val_loss: 0.4134\n",
      "Epoch 758/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9098 - loss: 0.1513 - val_accuracy: 0.8298 - val_loss: 0.4113\n",
      "Epoch 759/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9255 - loss: 0.1641 - val_accuracy: 0.8511 - val_loss: 0.4177\n",
      "Epoch 760/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9100 - loss: 0.1691 - val_accuracy: 0.8298 - val_loss: 0.4234\n",
      "Epoch 761/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9284 - loss: 0.1426 - val_accuracy: 0.8511 - val_loss: 0.4262\n",
      "Epoch 762/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9293 - loss: 0.1507 - val_accuracy: 0.8723 - val_loss: 0.4060\n",
      "Epoch 763/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9379 - loss: 0.1398 - val_accuracy: 0.8298 - val_loss: 0.4003\n",
      "Epoch 764/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9167 - loss: 0.1403 - val_accuracy: 0.8936 - val_loss: 0.4202\n",
      "Epoch 765/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9218 - loss: 0.1515 - val_accuracy: 0.8511 - val_loss: 0.4220\n",
      "Epoch 766/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9271 - loss: 0.1436 - val_accuracy: 0.8298 - val_loss: 0.4227\n",
      "Epoch 767/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9393 - loss: 0.1491 - val_accuracy: 0.8723 - val_loss: 0.4258\n",
      "Epoch 768/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9180 - loss: 0.1687 - val_accuracy: 0.8298 - val_loss: 0.4169\n",
      "Epoch 769/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9261 - loss: 0.1575 - val_accuracy: 0.8723 - val_loss: 0.4156\n",
      "Epoch 770/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9121 - loss: 0.1577 - val_accuracy: 0.8723 - val_loss: 0.4301\n",
      "Epoch 771/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9287 - loss: 0.1560 - val_accuracy: 0.8298 - val_loss: 0.4248\n",
      "Epoch 772/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9506 - loss: 0.1297 - val_accuracy: 0.8298 - val_loss: 0.4198\n",
      "Epoch 773/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9306 - loss: 0.1553 - val_accuracy: 0.8723 - val_loss: 0.4263\n",
      "Epoch 774/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9307 - loss: 0.1518 - val_accuracy: 0.8298 - val_loss: 0.4161\n",
      "Epoch 775/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9412 - loss: 0.1411 - val_accuracy: 0.8723 - val_loss: 0.4304\n",
      "Epoch 776/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9273 - loss: 0.1278 - val_accuracy: 0.8723 - val_loss: 0.4266\n",
      "Epoch 777/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9215 - loss: 0.1541 - val_accuracy: 0.8511 - val_loss: 0.4193\n",
      "Epoch 778/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9271 - loss: 0.1466 - val_accuracy: 0.8511 - val_loss: 0.4203\n",
      "Epoch 779/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9315 - loss: 0.1395 - val_accuracy: 0.8723 - val_loss: 0.4257\n",
      "Epoch 780/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9121 - loss: 0.1638 - val_accuracy: 0.8298 - val_loss: 0.4248\n",
      "Epoch 781/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9288 - loss: 0.1580 - val_accuracy: 0.8723 - val_loss: 0.4317\n",
      "Epoch 782/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9327 - loss: 0.1468 - val_accuracy: 0.8298 - val_loss: 0.4184\n",
      "Epoch 783/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9219 - loss: 0.1523 - val_accuracy: 0.8723 - val_loss: 0.4301\n",
      "Epoch 784/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9128 - loss: 0.1720 - val_accuracy: 0.8298 - val_loss: 0.4250\n",
      "Epoch 785/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9167 - loss: 0.1693 - val_accuracy: 0.8723 - val_loss: 0.4307\n",
      "Epoch 786/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9137 - loss: 0.1564 - val_accuracy: 0.8298 - val_loss: 0.4279\n",
      "Epoch 787/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9171 - loss: 0.1487 - val_accuracy: 0.8723 - val_loss: 0.4268\n",
      "Epoch 788/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9284 - loss: 0.1546 - val_accuracy: 0.8723 - val_loss: 0.4353\n",
      "Epoch 789/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9269 - loss: 0.1584 - val_accuracy: 0.8298 - val_loss: 0.4262\n",
      "Epoch 790/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9114 - loss: 0.1736 - val_accuracy: 0.8511 - val_loss: 0.4280\n",
      "Epoch 791/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9204 - loss: 0.1447 - val_accuracy: 0.8298 - val_loss: 0.4343\n",
      "Epoch 792/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9247 - loss: 0.1533 - val_accuracy: 0.8298 - val_loss: 0.4295\n",
      "Epoch 793/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8871 - loss: 0.1640 - val_accuracy: 0.8511 - val_loss: 0.4345\n",
      "Epoch 794/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9323 - loss: 0.1484 - val_accuracy: 0.8298 - val_loss: 0.4300\n",
      "Epoch 795/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9187 - loss: 0.1666 - val_accuracy: 0.8298 - val_loss: 0.4344\n",
      "Epoch 796/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9303 - loss: 0.1550 - val_accuracy: 0.8723 - val_loss: 0.4341\n",
      "Epoch 797/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9359 - loss: 0.1455 - val_accuracy: 0.8298 - val_loss: 0.4265\n",
      "Epoch 798/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9436 - loss: 0.1435 - val_accuracy: 0.8511 - val_loss: 0.4313\n",
      "Epoch 799/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9068 - loss: 0.1639 - val_accuracy: 0.8298 - val_loss: 0.4336\n",
      "Epoch 800/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9191 - loss: 0.1357 - val_accuracy: 0.8298 - val_loss: 0.4273\n",
      "Epoch 801/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9290 - loss: 0.1473 - val_accuracy: 0.8723 - val_loss: 0.4324\n",
      "Epoch 802/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9460 - loss: 0.1287 - val_accuracy: 0.8298 - val_loss: 0.4355\n",
      "Epoch 803/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9283 - loss: 0.1503 - val_accuracy: 0.8298 - val_loss: 0.4340\n",
      "Epoch 804/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9457 - loss: 0.1335 - val_accuracy: 0.8723 - val_loss: 0.4419\n",
      "Epoch 805/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9395 - loss: 0.1238 - val_accuracy: 0.8298 - val_loss: 0.4282\n",
      "Epoch 806/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9194 - loss: 0.1700 - val_accuracy: 0.8298 - val_loss: 0.4336\n",
      "Epoch 807/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9195 - loss: 0.1632 - val_accuracy: 0.8723 - val_loss: 0.4439\n",
      "Epoch 808/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9409 - loss: 0.1262 - val_accuracy: 0.8298 - val_loss: 0.4326\n",
      "Epoch 809/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9460 - loss: 0.1421 - val_accuracy: 0.8511 - val_loss: 0.4402\n",
      "Epoch 810/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9232 - loss: 0.1469 - val_accuracy: 0.8511 - val_loss: 0.4363\n",
      "Epoch 811/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9443 - loss: 0.1394 - val_accuracy: 0.8298 - val_loss: 0.4369\n",
      "Epoch 812/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9264 - loss: 0.1548 - val_accuracy: 0.8511 - val_loss: 0.4414\n",
      "Epoch 813/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9301 - loss: 0.1544 - val_accuracy: 0.8298 - val_loss: 0.4287\n",
      "Epoch 814/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9209 - loss: 0.1420 - val_accuracy: 0.8298 - val_loss: 0.4294\n",
      "Epoch 815/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9326 - loss: 0.1318 - val_accuracy: 0.8723 - val_loss: 0.4448\n",
      "Epoch 816/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9465 - loss: 0.1368 - val_accuracy: 0.8298 - val_loss: 0.4401\n",
      "Epoch 817/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9263 - loss: 0.1484 - val_accuracy: 0.8511 - val_loss: 0.4443\n",
      "Epoch 818/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9374 - loss: 0.1520 - val_accuracy: 0.8085 - val_loss: 0.4347\n",
      "Epoch 819/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9487 - loss: 0.1397 - val_accuracy: 0.8723 - val_loss: 0.4497\n",
      "Epoch 820/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9179 - loss: 0.1444 - val_accuracy: 0.8723 - val_loss: 0.4384\n",
      "Epoch 821/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9220 - loss: 0.1434 - val_accuracy: 0.8298 - val_loss: 0.4248\n",
      "Epoch 822/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9329 - loss: 0.1511 - val_accuracy: 0.8723 - val_loss: 0.4522\n",
      "Epoch 823/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9210 - loss: 0.1516 - val_accuracy: 0.8298 - val_loss: 0.4407\n",
      "Epoch 824/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9441 - loss: 0.1408 - val_accuracy: 0.8298 - val_loss: 0.4393\n",
      "Epoch 825/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9203 - loss: 0.1382 - val_accuracy: 0.8723 - val_loss: 0.4484\n",
      "Epoch 826/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9423 - loss: 0.1353 - val_accuracy: 0.8085 - val_loss: 0.4521\n",
      "Epoch 827/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9401 - loss: 0.1478 - val_accuracy: 0.8085 - val_loss: 0.4548\n",
      "Epoch 828/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9065 - loss: 0.1794 - val_accuracy: 0.8511 - val_loss: 0.4438\n",
      "Epoch 829/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9184 - loss: 0.1634 - val_accuracy: 0.8511 - val_loss: 0.4441\n",
      "Epoch 830/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9472 - loss: 0.1350 - val_accuracy: 0.8723 - val_loss: 0.4565\n",
      "Epoch 831/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9119 - loss: 0.1639 - val_accuracy: 0.8298 - val_loss: 0.4420\n",
      "Epoch 832/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9370 - loss: 0.1521 - val_accuracy: 0.8723 - val_loss: 0.4493\n",
      "Epoch 833/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9255 - loss: 0.1539 - val_accuracy: 0.8298 - val_loss: 0.4354\n",
      "Epoch 834/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9576 - loss: 0.1212 - val_accuracy: 0.8511 - val_loss: 0.4419\n",
      "Epoch 835/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9358 - loss: 0.1301 - val_accuracy: 0.8298 - val_loss: 0.4494\n",
      "Epoch 836/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9308 - loss: 0.1316 - val_accuracy: 0.8298 - val_loss: 0.4437\n",
      "Epoch 837/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9298 - loss: 0.1624 - val_accuracy: 0.8298 - val_loss: 0.4361\n",
      "Epoch 838/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9012 - loss: 0.1597 - val_accuracy: 0.8723 - val_loss: 0.4496\n",
      "Epoch 839/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9236 - loss: 0.1348 - val_accuracy: 0.8298 - val_loss: 0.4462\n",
      "Epoch 840/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9363 - loss: 0.1345 - val_accuracy: 0.8511 - val_loss: 0.4501\n",
      "Epoch 841/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9320 - loss: 0.1420 - val_accuracy: 0.8298 - val_loss: 0.4495\n",
      "Epoch 842/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9331 - loss: 0.1309 - val_accuracy: 0.8298 - val_loss: 0.4461\n",
      "Epoch 843/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9440 - loss: 0.1266 - val_accuracy: 0.8511 - val_loss: 0.4465\n",
      "Epoch 844/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9296 - loss: 0.1401 - val_accuracy: 0.8511 - val_loss: 0.4576\n",
      "Epoch 845/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9331 - loss: 0.1452 - val_accuracy: 0.8298 - val_loss: 0.4522\n",
      "Epoch 846/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9360 - loss: 0.1259 - val_accuracy: 0.8298 - val_loss: 0.4514\n",
      "Epoch 847/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8948 - loss: 0.1575 - val_accuracy: 0.8298 - val_loss: 0.4434\n",
      "Epoch 848/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9391 - loss: 0.1141 - val_accuracy: 0.8723 - val_loss: 0.4470\n",
      "Epoch 849/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9180 - loss: 0.1264 - val_accuracy: 0.8298 - val_loss: 0.4470\n",
      "Epoch 850/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9328 - loss: 0.1629 - val_accuracy: 0.8723 - val_loss: 0.4627\n",
      "Epoch 851/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9206 - loss: 0.1392 - val_accuracy: 0.8298 - val_loss: 0.4558\n",
      "Epoch 852/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9389 - loss: 0.1373 - val_accuracy: 0.8298 - val_loss: 0.4558\n",
      "Epoch 853/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9265 - loss: 0.1348 - val_accuracy: 0.8298 - val_loss: 0.4569\n",
      "Epoch 854/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9330 - loss: 0.1419 - val_accuracy: 0.8298 - val_loss: 0.4562\n",
      "Epoch 855/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9123 - loss: 0.1517 - val_accuracy: 0.8298 - val_loss: 0.4564\n",
      "Epoch 856/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9320 - loss: 0.1281 - val_accuracy: 0.8723 - val_loss: 0.4775\n",
      "Epoch 857/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9198 - loss: 0.1502 - val_accuracy: 0.8298 - val_loss: 0.4556\n",
      "Epoch 858/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9456 - loss: 0.1311 - val_accuracy: 0.8298 - val_loss: 0.4575\n",
      "Epoch 859/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9441 - loss: 0.1327 - val_accuracy: 0.8298 - val_loss: 0.4504\n",
      "Epoch 860/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9000 - loss: 0.1525 - val_accuracy: 0.8298 - val_loss: 0.4512\n",
      "Epoch 861/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9160 - loss: 0.1484 - val_accuracy: 0.8511 - val_loss: 0.4548\n",
      "Epoch 862/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9130 - loss: 0.1646 - val_accuracy: 0.8298 - val_loss: 0.4579\n",
      "Epoch 863/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9231 - loss: 0.1373 - val_accuracy: 0.8298 - val_loss: 0.4642\n",
      "Epoch 864/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9315 - loss: 0.1327 - val_accuracy: 0.8298 - val_loss: 0.4582\n",
      "Epoch 865/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9247 - loss: 0.1481 - val_accuracy: 0.8511 - val_loss: 0.4604\n",
      "Epoch 866/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9141 - loss: 0.1461 - val_accuracy: 0.8298 - val_loss: 0.4560\n",
      "Epoch 867/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9143 - loss: 0.1364 - val_accuracy: 0.8085 - val_loss: 0.4595\n",
      "Epoch 868/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9401 - loss: 0.1280 - val_accuracy: 0.8298 - val_loss: 0.4562\n",
      "Epoch 869/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9580 - loss: 0.1157 - val_accuracy: 0.8298 - val_loss: 0.4605\n",
      "Epoch 870/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9388 - loss: 0.1311 - val_accuracy: 0.8298 - val_loss: 0.4650\n",
      "Epoch 871/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9372 - loss: 0.1304 - val_accuracy: 0.8298 - val_loss: 0.4607\n",
      "Epoch 872/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9325 - loss: 0.1348 - val_accuracy: 0.8298 - val_loss: 0.4581\n",
      "Epoch 873/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9383 - loss: 0.1466 - val_accuracy: 0.8298 - val_loss: 0.4618\n",
      "Epoch 874/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9343 - loss: 0.1370 - val_accuracy: 0.8298 - val_loss: 0.4630\n",
      "Epoch 875/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9301 - loss: 0.1400 - val_accuracy: 0.8298 - val_loss: 0.4481\n",
      "Epoch 876/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9172 - loss: 0.1346 - val_accuracy: 0.8723 - val_loss: 0.4608\n",
      "Epoch 877/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9326 - loss: 0.1265 - val_accuracy: 0.8298 - val_loss: 0.4598\n",
      "Epoch 878/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9412 - loss: 0.1403 - val_accuracy: 0.8298 - val_loss: 0.4566\n",
      "Epoch 879/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9223 - loss: 0.1342 - val_accuracy: 0.8511 - val_loss: 0.4689\n",
      "Epoch 880/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9340 - loss: 0.1368 - val_accuracy: 0.8298 - val_loss: 0.4636\n",
      "Epoch 881/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9419 - loss: 0.1465 - val_accuracy: 0.8298 - val_loss: 0.4702\n",
      "Epoch 882/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9401 - loss: 0.1240 - val_accuracy: 0.8085 - val_loss: 0.4638\n",
      "Epoch 883/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8959 - loss: 0.1446 - val_accuracy: 0.8298 - val_loss: 0.4699\n",
      "Epoch 884/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9221 - loss: 0.1310 - val_accuracy: 0.8298 - val_loss: 0.4677\n",
      "Epoch 885/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9073 - loss: 0.1478 - val_accuracy: 0.8298 - val_loss: 0.4708\n",
      "Epoch 886/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9246 - loss: 0.1549 - val_accuracy: 0.8085 - val_loss: 0.4712\n",
      "Epoch 887/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9246 - loss: 0.1308 - val_accuracy: 0.8298 - val_loss: 0.4710\n",
      "Epoch 888/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9188 - loss: 0.1428 - val_accuracy: 0.8298 - val_loss: 0.4582\n",
      "Epoch 889/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9417 - loss: 0.1345 - val_accuracy: 0.8723 - val_loss: 0.4698\n",
      "Epoch 890/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9391 - loss: 0.1173 - val_accuracy: 0.8298 - val_loss: 0.4660\n",
      "Epoch 891/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9396 - loss: 0.1248 - val_accuracy: 0.8723 - val_loss: 0.4798\n",
      "Epoch 892/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9116 - loss: 0.1566 - val_accuracy: 0.8298 - val_loss: 0.4663\n",
      "Epoch 893/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9299 - loss: 0.1450 - val_accuracy: 0.8511 - val_loss: 0.4684\n",
      "Epoch 894/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9202 - loss: 0.1471 - val_accuracy: 0.8723 - val_loss: 0.4939\n",
      "Epoch 895/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9434 - loss: 0.1284 - val_accuracy: 0.8298 - val_loss: 0.4651\n",
      "Epoch 896/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9505 - loss: 0.1396 - val_accuracy: 0.8723 - val_loss: 0.4818\n",
      "Epoch 897/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9211 - loss: 0.1252 - val_accuracy: 0.8298 - val_loss: 0.4671\n",
      "Epoch 898/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9411 - loss: 0.1414 - val_accuracy: 0.8298 - val_loss: 0.4611\n",
      "Epoch 899/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9370 - loss: 0.1302 - val_accuracy: 0.8511 - val_loss: 0.4766\n",
      "Epoch 900/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9434 - loss: 0.1353 - val_accuracy: 0.8298 - val_loss: 0.4686\n",
      "Epoch 901/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9300 - loss: 0.1258 - val_accuracy: 0.8298 - val_loss: 0.4700\n",
      "Epoch 902/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9478 - loss: 0.1140 - val_accuracy: 0.8511 - val_loss: 0.4787\n",
      "Epoch 903/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9213 - loss: 0.1446 - val_accuracy: 0.8298 - val_loss: 0.4638\n",
      "Epoch 904/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9454 - loss: 0.1272 - val_accuracy: 0.8723 - val_loss: 0.4933\n",
      "Epoch 905/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9108 - loss: 0.1375 - val_accuracy: 0.8085 - val_loss: 0.4743\n",
      "Epoch 906/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9592 - loss: 0.1163 - val_accuracy: 0.8723 - val_loss: 0.4879\n",
      "Epoch 907/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9184 - loss: 0.1389 - val_accuracy: 0.8298 - val_loss: 0.4737\n",
      "Epoch 908/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9404 - loss: 0.1204 - val_accuracy: 0.8298 - val_loss: 0.4643\n",
      "Epoch 909/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9127 - loss: 0.1558 - val_accuracy: 0.8511 - val_loss: 0.4787\n",
      "Epoch 910/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9169 - loss: 0.1547 - val_accuracy: 0.8298 - val_loss: 0.4792\n",
      "Epoch 911/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9227 - loss: 0.1260 - val_accuracy: 0.8511 - val_loss: 0.4781\n",
      "Epoch 912/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9266 - loss: 0.1322 - val_accuracy: 0.8511 - val_loss: 0.4734\n",
      "Epoch 913/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9449 - loss: 0.1255 - val_accuracy: 0.8511 - val_loss: 0.4779\n",
      "Epoch 914/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9424 - loss: 0.1313 - val_accuracy: 0.8511 - val_loss: 0.4821\n",
      "Epoch 915/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9124 - loss: 0.1719 - val_accuracy: 0.8085 - val_loss: 0.4694\n",
      "Epoch 916/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9643 - loss: 0.1239 - val_accuracy: 0.8723 - val_loss: 0.4910\n",
      "Epoch 917/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8968 - loss: 0.1595 - val_accuracy: 0.8511 - val_loss: 0.4845\n",
      "Epoch 918/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9285 - loss: 0.1424 - val_accuracy: 0.8298 - val_loss: 0.4746\n",
      "Epoch 919/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9479 - loss: 0.1273 - val_accuracy: 0.8723 - val_loss: 0.4929\n",
      "Epoch 920/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9388 - loss: 0.1177 - val_accuracy: 0.8298 - val_loss: 0.4815\n",
      "Epoch 921/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9348 - loss: 0.1389 - val_accuracy: 0.8298 - val_loss: 0.4732\n",
      "Epoch 922/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9138 - loss: 0.1587 - val_accuracy: 0.8723 - val_loss: 0.4999\n",
      "Epoch 923/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9250 - loss: 0.1424 - val_accuracy: 0.8298 - val_loss: 0.4770\n",
      "Epoch 924/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9264 - loss: 0.1361 - val_accuracy: 0.8723 - val_loss: 0.4924\n",
      "Epoch 925/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9383 - loss: 0.1303 - val_accuracy: 0.8298 - val_loss: 0.4831\n",
      "Epoch 926/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9404 - loss: 0.1318 - val_accuracy: 0.8511 - val_loss: 0.4850\n",
      "Epoch 927/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9244 - loss: 0.1380 - val_accuracy: 0.8511 - val_loss: 0.4890\n",
      "Epoch 928/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9368 - loss: 0.1222 - val_accuracy: 0.8511 - val_loss: 0.4883\n",
      "Epoch 929/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9437 - loss: 0.1117 - val_accuracy: 0.8298 - val_loss: 0.4898\n",
      "Epoch 930/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9342 - loss: 0.1220 - val_accuracy: 0.8298 - val_loss: 0.4954\n",
      "Epoch 931/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9223 - loss: 0.1442 - val_accuracy: 0.8298 - val_loss: 0.4880\n",
      "Epoch 932/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9536 - loss: 0.1099 - val_accuracy: 0.8298 - val_loss: 0.4915\n",
      "Epoch 933/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9379 - loss: 0.1172 - val_accuracy: 0.8511 - val_loss: 0.4883\n",
      "Epoch 934/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9509 - loss: 0.1172 - val_accuracy: 0.8511 - val_loss: 0.4870\n",
      "Epoch 935/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9219 - loss: 0.1328 - val_accuracy: 0.8298 - val_loss: 0.4917\n",
      "Epoch 936/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9382 - loss: 0.1255 - val_accuracy: 0.8085 - val_loss: 0.4922\n",
      "Epoch 937/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9396 - loss: 0.1268 - val_accuracy: 0.8511 - val_loss: 0.4932\n",
      "Epoch 938/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9391 - loss: 0.1291 - val_accuracy: 0.8298 - val_loss: 0.4712\n",
      "Epoch 939/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9256 - loss: 0.1354 - val_accuracy: 0.8723 - val_loss: 0.4850\n",
      "Epoch 940/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9423 - loss: 0.1201 - val_accuracy: 0.8298 - val_loss: 0.4957\n",
      "Epoch 941/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9410 - loss: 0.1051 - val_accuracy: 0.8298 - val_loss: 0.4915\n",
      "Epoch 942/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9279 - loss: 0.1321 - val_accuracy: 0.8511 - val_loss: 0.5018\n",
      "Epoch 943/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9208 - loss: 0.1417 - val_accuracy: 0.8298 - val_loss: 0.4961\n",
      "Epoch 944/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9339 - loss: 0.1247 - val_accuracy: 0.8298 - val_loss: 0.4927\n",
      "Epoch 945/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9530 - loss: 0.1264 - val_accuracy: 0.8511 - val_loss: 0.5022\n",
      "Epoch 946/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9046 - loss: 0.1460 - val_accuracy: 0.8511 - val_loss: 0.4975\n",
      "Epoch 947/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9211 - loss: 0.1318 - val_accuracy: 0.8723 - val_loss: 0.5048\n",
      "Epoch 948/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9307 - loss: 0.1350 - val_accuracy: 0.8511 - val_loss: 0.4942\n",
      "Epoch 949/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9439 - loss: 0.1207 - val_accuracy: 0.8511 - val_loss: 0.4960\n",
      "Epoch 950/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9348 - loss: 0.1221 - val_accuracy: 0.8298 - val_loss: 0.4999\n",
      "Epoch 951/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9458 - loss: 0.1149 - val_accuracy: 0.8298 - val_loss: 0.4910\n",
      "Epoch 952/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9327 - loss: 0.1354 - val_accuracy: 0.8298 - val_loss: 0.4978\n",
      "Epoch 953/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9211 - loss: 0.1341 - val_accuracy: 0.8298 - val_loss: 0.4946\n",
      "Epoch 954/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9434 - loss: 0.1130 - val_accuracy: 0.8511 - val_loss: 0.4976\n",
      "Epoch 955/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9340 - loss: 0.1271 - val_accuracy: 0.8511 - val_loss: 0.5064\n",
      "Epoch 956/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9341 - loss: 0.1369 - val_accuracy: 0.8298 - val_loss: 0.5000\n",
      "Epoch 957/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9272 - loss: 0.1332 - val_accuracy: 0.8511 - val_loss: 0.5030\n",
      "Epoch 958/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9021 - loss: 0.1370 - val_accuracy: 0.8511 - val_loss: 0.5006\n",
      "Epoch 959/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9389 - loss: 0.1126 - val_accuracy: 0.8298 - val_loss: 0.4978\n",
      "Epoch 960/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9280 - loss: 0.1403 - val_accuracy: 0.8298 - val_loss: 0.5037\n",
      "Epoch 961/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9392 - loss: 0.1077 - val_accuracy: 0.8298 - val_loss: 0.5178\n",
      "Epoch 962/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9227 - loss: 0.1217 - val_accuracy: 0.8298 - val_loss: 0.5071\n",
      "Epoch 963/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9267 - loss: 0.1401 - val_accuracy: 0.8298 - val_loss: 0.4969\n",
      "Epoch 964/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9207 - loss: 0.1118 - val_accuracy: 0.8511 - val_loss: 0.5067\n",
      "Epoch 965/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9247 - loss: 0.1334 - val_accuracy: 0.8511 - val_loss: 0.5022\n",
      "Epoch 966/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9404 - loss: 0.1283 - val_accuracy: 0.8298 - val_loss: 0.4982\n",
      "Epoch 967/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9533 - loss: 0.1197 - val_accuracy: 0.8298 - val_loss: 0.5154\n",
      "Epoch 968/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9173 - loss: 0.1450 - val_accuracy: 0.8298 - val_loss: 0.5028\n",
      "Epoch 969/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9478 - loss: 0.1300 - val_accuracy: 0.8298 - val_loss: 0.5001\n",
      "Epoch 970/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9248 - loss: 0.1391 - val_accuracy: 0.8511 - val_loss: 0.5115\n",
      "Epoch 971/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9397 - loss: 0.1130 - val_accuracy: 0.8298 - val_loss: 0.5134\n",
      "Epoch 972/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9405 - loss: 0.1153 - val_accuracy: 0.8511 - val_loss: 0.5018\n",
      "Epoch 973/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9434 - loss: 0.1214 - val_accuracy: 0.8511 - val_loss: 0.5065\n",
      "Epoch 974/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9450 - loss: 0.1239 - val_accuracy: 0.8298 - val_loss: 0.5044\n",
      "Epoch 975/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9386 - loss: 0.1130 - val_accuracy: 0.8511 - val_loss: 0.5103\n",
      "Epoch 976/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9446 - loss: 0.1124 - val_accuracy: 0.8298 - val_loss: 0.5147\n",
      "Epoch 977/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9337 - loss: 0.1240 - val_accuracy: 0.8298 - val_loss: 0.5097\n",
      "Epoch 978/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9405 - loss: 0.1135 - val_accuracy: 0.8298 - val_loss: 0.5176\n",
      "Epoch 979/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9251 - loss: 0.1401 - val_accuracy: 0.8298 - val_loss: 0.5129\n",
      "Epoch 980/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9376 - loss: 0.1143 - val_accuracy: 0.8511 - val_loss: 0.5050\n",
      "Epoch 981/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9290 - loss: 0.1347 - val_accuracy: 0.8511 - val_loss: 0.5085\n",
      "Epoch 982/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9322 - loss: 0.1268 - val_accuracy: 0.8298 - val_loss: 0.5088\n",
      "Epoch 983/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9461 - loss: 0.1088 - val_accuracy: 0.8298 - val_loss: 0.5044\n",
      "Epoch 984/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9130 - loss: 0.1349 - val_accuracy: 0.8298 - val_loss: 0.5203\n",
      "Epoch 985/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9494 - loss: 0.1206 - val_accuracy: 0.8298 - val_loss: 0.5178\n",
      "Epoch 986/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9564 - loss: 0.1087 - val_accuracy: 0.8298 - val_loss: 0.5054\n",
      "Epoch 987/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9622 - loss: 0.1088 - val_accuracy: 0.8511 - val_loss: 0.5245\n",
      "Epoch 988/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9222 - loss: 0.1334 - val_accuracy: 0.8298 - val_loss: 0.5142\n",
      "Epoch 989/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9604 - loss: 0.1073 - val_accuracy: 0.8511 - val_loss: 0.5067\n",
      "Epoch 990/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9119 - loss: 0.1375 - val_accuracy: 0.8511 - val_loss: 0.5273\n",
      "Epoch 991/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9330 - loss: 0.1311 - val_accuracy: 0.8298 - val_loss: 0.5153\n",
      "Epoch 992/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9361 - loss: 0.1054 - val_accuracy: 0.8298 - val_loss: 0.5094\n",
      "Epoch 993/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9459 - loss: 0.1027 - val_accuracy: 0.8298 - val_loss: 0.5177\n",
      "Epoch 994/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9073 - loss: 0.1474 - val_accuracy: 0.8511 - val_loss: 0.5024\n",
      "Epoch 995/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9378 - loss: 0.1160 - val_accuracy: 0.8298 - val_loss: 0.5176\n",
      "Epoch 996/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9240 - loss: 0.1348 - val_accuracy: 0.8298 - val_loss: 0.5240\n",
      "Epoch 997/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9278 - loss: 0.1272 - val_accuracy: 0.8298 - val_loss: 0.5113\n",
      "Epoch 998/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9450 - loss: 0.1179 - val_accuracy: 0.8298 - val_loss: 0.5248\n",
      "Epoch 999/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9329 - loss: 0.1169 - val_accuracy: 0.8511 - val_loss: 0.5218\n",
      "Epoch 1000/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9395 - loss: 0.1370 - val_accuracy: 0.8298 - val_loss: 0.5139\n"
     ]
    }
   ],
   "source": [
    "history = model_tf.fit(X_train.values, y_train_enc, epochs=1000, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">700</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">10,100</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">10,100</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">101</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │           \u001b[38;5;34m700\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │        \u001b[38;5;34m10,100\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │        \u001b[38;5;34m10,100\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │           \u001b[38;5;34m101\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">63,005</span> (246.12 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m63,005\u001b[0m (246.12 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">21,001</span> (82.04 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m21,001\u001b[0m (82.04 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">42,004</span> (164.08 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m42,004\u001b[0m (164.08 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_tf.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7998 - loss: 0.6988 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.7284644842147827, 0.7948718070983887]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_tf.evaluate(X_test, y_test_enc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss(history, which='loss'):\n",
    "    plt.plot(history.history[which], label='train')\n",
    "    try:\n",
    "        plt.plot(history.history['val_'+which], label='validation')\n",
    "    except:\n",
    "        None\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel(which)\n",
    "    plt.legend()\n",
    "    plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_loss(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_loss(history, 'accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So probably shouldn't go for 1000 epochs, there's overfitting there"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm going to implement Early Stopping. It's a form of regularisation - to try to prevent overfitting, and it also will train our model more quickly.\n",
    "\n",
    "<a href=\"https://en.wikipedia.org/wiki/Early_stopping\">Wikipedia Link</a>\n",
    "\n",
    "<a href=\"https://machinelearningmastery.com/how-to-stop-training-deep-neural-networks-at-the-right-time-using-early-stopping/\">More Early Stopping Detail</a>\n",
    "\n",
    "<a href=\"https://towardsdatascience.com/early-stopping-a-cool-strategy-to-regularize-neural-networks-bfdeca6d722e\">Another Link</a>\n",
    "\n",
    "I mentioned it in lectures without going into any detail and will talk about it more next week.\n",
    "\n",
    "The basic idea is, monitor how well the validation set is performing after every epoch, if there has not been any improvement in its score for a while (say in 10 epochs or whatever you pick as your \"patience\" - we don't just say over 1 epoch as training could just be \"stuck\"). MLPClassifier in sklearn has it sort of implemented and we saw it  above \"Training loss did not improve more than tol=0.000000 for 10 consecutive epochs. Stopping.\"\n",
    "\n",
    "It is added as a callback function that checks for what we want"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Be careful with restore_best_weights see https://medium.com/@doleron/never-use-restore-best-weights-true-with-earlystopping-754ba5f9b0c6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#callback_modelcheckpoint_loss = tf.keras.callbacks.ModelCheckpoint(filepath='best_model_loss.keras', monitor='val_loss', save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_tf2 = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(100),\n",
    "    tf.keras.layers.Dense(100),\n",
    "    tf.keras.layers.Dense(100),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_tf2.compile(\n",
    "     optimizer=tf.keras.optimizers.Adam(0.001),\n",
    "    loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "    metrics=['accuracy'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.5776 - loss: 7.4458 - val_accuracy: 0.7660 - val_loss: 1.5008\n",
      "Epoch 2/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7778 - loss: 1.9696 - val_accuracy: 0.7660 - val_loss: 0.9691\n",
      "Epoch 3/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7756 - loss: 1.9785 - val_accuracy: 0.7021 - val_loss: 1.6782\n",
      "Epoch 4/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6665 - loss: 1.9295 - val_accuracy: 0.7872 - val_loss: 0.9367\n",
      "Epoch 5/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7376 - loss: 1.1798 - val_accuracy: 0.8085 - val_loss: 0.6610\n",
      "Epoch 6/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8387 - loss: 0.8680 - val_accuracy: 0.8936 - val_loss: 0.5839\n",
      "Epoch 7/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7235 - loss: 1.2574 - val_accuracy: 0.8723 - val_loss: 0.6803\n",
      "Epoch 8/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7466 - loss: 1.1769 - val_accuracy: 0.8936 - val_loss: 0.4241\n",
      "Epoch 9/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7715 - loss: 0.8132 - val_accuracy: 0.8298 - val_loss: 0.7484\n",
      "Epoch 10/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7812 - loss: 0.8044 - val_accuracy: 0.8085 - val_loss: 0.7842\n",
      "Epoch 11/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7916 - loss: 0.9609 - val_accuracy: 0.8723 - val_loss: 0.3155\n",
      "Epoch 12/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7833 - loss: 0.7253 - val_accuracy: 0.8936 - val_loss: 0.4015\n",
      "Epoch 13/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7664 - loss: 0.7486 - val_accuracy: 0.8936 - val_loss: 0.3376\n",
      "Epoch 14/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7906 - loss: 0.6323 - val_accuracy: 0.8936 - val_loss: 0.3183\n",
      "Epoch 15/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8407 - loss: 0.4620 - val_accuracy: 0.8936 - val_loss: 0.2350\n",
      "Epoch 16/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8169 - loss: 0.4458 - val_accuracy: 0.8298 - val_loss: 0.3923\n",
      "Epoch 17/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7762 - loss: 0.5251 - val_accuracy: 0.8936 - val_loss: 0.2425\n",
      "Epoch 18/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7663 - loss: 0.4499 - val_accuracy: 0.8723 - val_loss: 0.3488\n",
      "Epoch 19/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7697 - loss: 0.5514 - val_accuracy: 0.8511 - val_loss: 0.3029\n",
      "Epoch 20/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8120 - loss: 0.4287 - val_accuracy: 0.8936 - val_loss: 0.2714\n",
      "Epoch 21/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8113 - loss: 0.4004 - val_accuracy: 0.8936 - val_loss: 0.2462\n",
      "Epoch 22/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7571 - loss: 0.4274 - val_accuracy: 0.7660 - val_loss: 0.4514\n",
      "Epoch 23/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7178 - loss: 0.5649 - val_accuracy: 0.7234 - val_loss: 0.6953\n",
      "Epoch 24/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6972 - loss: 0.7883 - val_accuracy: 0.8936 - val_loss: 0.2553\n",
      "Epoch 25/1000\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7947 - loss: 0.5128 - val_accuracy: 0.7447 - val_loss: 0.7373\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x717e3a97b170>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_tf2.fit(X_train.values, y_train_enc, epochs=1000, validation_split=0.2, callbacks=[callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I said go for 1000 epochs, but will only go for a certain amount due to early stopping\n",
    "\n",
    "I also said to restore_best_weights, so it should be the model with the lowest val_loss that was found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7817 - loss: 0.4528 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.45680320262908936, 0.7820512652397156]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_tf2.evaluate(X_test, y_test_enc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This may be worse than sklearn still\n",
    "\n",
    "Anything you run may be different due to randomisation of batches etc\n",
    "\n",
    "You can try adding regularisation. Using a different loss/optimizer and other things to improve your model. Also there is going to be some random chance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "_change_revision": 80,
  "_is_fork": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
